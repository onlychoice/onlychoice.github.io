<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[SHOW ME THE CODE]]></title>
  <link href="http://onlychoice.github.io/atom.xml" rel="self"/>
  <link href="http://onlychoice.github.io/"/>
  <updated>2013-11-14T10:55:32+08:00</updated>
  <id>http://onlychoice.github.io/</id>
  <author>
    <name><![CDATA[Zhihui Jiao]]></name>
    <email><![CDATA[jzhihui521@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[RabbitMQ HA机制分析]]></title>
    <link href="http://onlychoice.github.io/blog/2013/11/12/rabbitmq-ha/"/>
    <updated>2013-11-12T11:05:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/11/12/rabbitmq-ha</id>
    <content type="html"><![CDATA[<h2>简介</h2>

<h2>创建HA队列</h2>

<h2>消息流程</h2>

<h3>发送消息</h3>

<p>需要回答这么几个问题：</p>

<blockquote><ul>
<li>由哪个角色（Master or Slave）来做这件事？流程是怎么样的？</li>
<li>在广播消息到多个Slave结点时，如果一个或者多个结点异常（网络延迟或者挂掉），有什么影响？</li>
<li>confirm是什么时候发回的？广播到所有结点都成功后还是只是发送成功？</li>
<li>为什么有时候confirm的时间会很长？</li>
</ul>
</blockquote>

<p>confirm什么时候会发回？</p>

<blockquote><ul>
<li>消息已经投递到一个消费者，并且这个消息不需要ack；</li>
<li></li>
</ul>
</blockquote>

<h3>消费消息</h3>

<blockquote><ul>
<li>流程是怎么样的？</li>
<li>Ack到服务器后如何处理的？</li>
</ul>
</blockquote>

<h2>节点变化</h2>

<h2>丢消息</h2>

<h2>运维</h2>

<h3>出现网络分区如何处理？</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[队列系统问题总结]]></title>
    <link href="http://onlychoice.github.io/blog/2013/10/30/summary-of-problems-occur-in-quueue-proxy/"/>
    <updated>2013-10-30T16:13:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/10/30/summary-of-problems-occur-in-quueue-proxy</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>对队列系统至今出现的各种问题进行总结。这个系统主要是分为这么几个部分：</p>

<blockquote><ul>
<li>RabbitMQ：消息broker；</li>
<li>Proxy：架在RabbitMQ前面，主要作用是负载均衡及高可用：消息可以路由到后端多个结点，任一结点的异常不会影响客户端；并且可以让RabbitMQ更方便的进行水平扩展；</li>
<li>客户端SDK：为了避免让产品方了解AMQP协议的细节（Exchange、bindings等），对标准的RabbitMQ客户端进行封装，只提供两个简单的接口：sendMessage，consumeMessage，并提供配置选项来定制客户端的行为。</li>
</ul>
</blockquote>

<!--more-->


<h2>Proxy无法接入TCP连接（代码问题）</h2>

<h3>现象</h3>

<p>客户端无法建立TCP连接，查看TCP状态发现：客户端TCP连接处于ESTABLISHED状态，但服务端TCP连接处于SYC_RECV状态。抓包发送服务端在三次握手的第二步向客户端发送了SYN+ACK后没有接受客户端的ACK数据，如下图：</p>

<p><img src="http://onlychoice.github.io/images/amqp_tcp_connect.png" /></p>

<p>客户端认为三步握手已经完成，但是服务端却一直在重传握手第二步的数据，导致客户端一直在重传握手正常完成后应该发送的第一个数据包（AMQP的协议头）。</p>

<h3>原因</h3>

<p>一开始不太清楚为什么TCP会处于这种状态，后经大牛提醒：服务端在未accept的情况下处于SYC_RECV状态，如下图所示：</p>

<p><img src="http://onlychoice.github.io/images/tcp_handshake.jpg" /></p>

<p>(注：图片引用自@淘叔度微博，accept应该是在要SYN_RECV状态之后发生，而不是之前)</p>

<p>知道这个原因的前提下，查看代码（网络部分代码使用的是RabbitMQ的代码），会发现类似下面的代码：</p>

<pre class="prettyprint linenums lang-erlang">
gen_event:which_handlers(error_logger),
prim_inet:async_accept(LSock, -1),
...
</pre>


<p>通过Erlang的Remote Shell进入Proxy进程查看，发现代码果然阻塞在gen_event:which_handlers/1这行。看注释这行的目的主要是为了清空日志进程的信箱，如果在特定环境（如内网）下可以不用。实现上可以简化为一个进程向另一个进程发送一条消息，然后等待响应，然后怀疑目标进程挂了，但是重试后发现目标进程正常。。。（上述进程都是指Erlang进程）</p>

<p>怀疑RabbitMQ是不是也会出现类似的问题，但是跑了一段时间的测试，发现RabbitMQ本身并没有出现这个问题。而Proxy与RabbitMQ在这块不一样的是使用了一个Erlang的日志框架<a href="https://github.com/basho/lager">lager</a>，难道跟这个有关系？去除lager依赖，再跑测试，问题不再出现。</p>

<h3>解决方案</h3>

<p>当前的解决方案是去除上面这句代码：gen_event:which_handlers/1，同时向lager的官方社区提了<a href="https://github.com/basho/lager/issues/176">issue</a>。</p>

<h2>客户端SDK死锁（代码问题）</h2>

<h3>现象</h3>

<p>在一次更新后，发现使用SDK的Tomcat进程在一段时间后会出现线程数激增，客户端无响应。把Thread状态dump出来以后，看到大量线程在等锁：</p>

<pre class="prettyprint linenums lang-java">
java.lang.Thread.State: BLOCKED (on object monitor)
    at com.netease.mq.client.AbstractSimpleClient.getChannel(AbstractSimpleClient.java:311)
    - waiting to lock <0x000000078b656bd8> (a com.netease.mq.client.producer.SimpleMessageProducer)
    at com.netease.mq.client.producer.SimpleMessageProducer.sendMessage(SimpleMessageProducer.java:78)
</pre>


<p>而持有锁的进程在等待Proxy的响应：</p>

<pre class="prettyprint linenums lang-java">
java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    at java.lang.Object.wait(Object.java:485)
    at com.rabbitmq.utility.BlockingCell.get(BlockingCell.java:50)
    - locked <0x00000007866a31c8> (a com.rabbitmq.utility.BlockingValueOrException)
    at com.rabbitmq.utility.BlockingCell.uninterruptibleGet(BlockingCell.java:89)
    - locked <0x00000007866a31c8> (a com.rabbitmq.utility.BlockingValueOrException)
    at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:33)
    at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:343)
    at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:216)
    at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:118)
    at com.rabbitmq.client.impl.ChannelN.confirmSelect(ChannelN.java:1052)
    at com.rabbitmq.client.impl.ChannelN.confirmSelect(ChannelN.java:61)
    at com.netease.mq.client.AbstractSimpleClient.createChannel(AbstractSimpleClient.java:342)
    at com.netease.mq.client.AbstractSimpleClient.getChannel(AbstractSimpleClient.java:323)
    - locked <0x000000078b656bd8> (a com.netease.mq.client.producer.SimpleMessageProducer)
    at com.netease.mq.client.producer.SimpleMessageProducer.sendMessage(SimpleMessageProducer.java:78)
</pre>


<p>看到这个堆栈的第一反应是Proxy出问题了，但是查看同一时间Proxy的日志显示，在路由消息（createChannel）到后端的时候发生了超时，并关闭了客户端连接。但是客户端竟然没有抛出异常，诡异。</p>

<h3>原因</h3>

<p>无意之间发现一个处于Waiting状态的线程，也在等待Proxy的响应：</p>

<pre class="prettyprint linenums lang-java">
java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    at java.lang.Object.wait(Object.java:485)
    at com.rabbitmq.utility.BlockingCell.get(BlockingCell.java:50)
    - locked <0x000000078669fc98> (a com.rabbitmq.utility.BlockingValueOrException)
    at com.rabbitmq.utility.BlockingCell.get(BlockingCell.java:65)
    - locked <0x000000078669fc98> (a com.rabbitmq.utility.BlockingValueOrException)
    at com.rabbitmq.utility.BlockingCell.uninterruptibleGet(BlockingCell.java:111)
    - locked <0x000000078669fc98> (a com.rabbitmq.utility.BlockingValueOrException)
    at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:37)
    at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:349)
    at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:567)
    at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:499)
    at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:492)
    at com.netease.mq.client.AbstractSimpleClient$1.onRemoval(AbstractSimpleClient.java:255)
    at com.google.common.cache.LocalCache.processPendingNotifications(LocalCache.java:2016)
    at com.google.common.cache.LocalCache$Segment.runUnlockedCleanup(LocalCache.java:3521)
    at com.google.common.cache.LocalCache$Segment.postWriteCleanup(LocalCache.java:3497)
    at com.google.common.cache.LocalCache$Segment.remove(LocalCache.java:3168)
    at com.google.common.cache.LocalCache.remove(LocalCache.java:4236)
    at com.google.common.cache.LocalCache$LocalManualCache.invalidate(LocalCache.java:4815)
    at com.netease.mq.client.AbstractSimpleClient$2.shutdownCompleted(AbstractSimpleClient.java:352)
</pre>


<p>看到这个线程的堆栈，可以确定Proxy关闭连接的事件客户端SDK已经捕捉到，并且触发了相关处理逻辑（AbstractSimpleClient$2.shutdownCompleted）。后面的逻辑就是导致死锁的更新的主要内容：根据需要回收已经过期的channel。这时候，客户端SDK会向Proxy发送一个channel.close命令，然后等待响应，但是连接已经关闭了，所以永远不可能等到响应。问题是：</p>

<blockquote><ul>
<li>这时候，需要回收的channel不知道连接已关闭？</li>
<li>就算不知道，在已关闭的连接上发送数据不会抛出异常？</li>
</ul>
</blockquote>

<p>为了重现这个现象，修改Proxy的代码，channel数量到一定水平，新打开channel时产生与上述问题一致的行为：等待会使channel过期的时间后关闭连接，可以稳定重现死锁。然后回答下上面的两个问题：</p>

<blockquote><ul>
<li>触发AbstractSimpleClient$2.shutdownCompleted逻辑的channel确实知道连接已经关闭，并且是第一个知道连接已经关闭的channel，其它的channel会依次得到通知；但是在第一个channel触发回收时，其它channel是不知道连接已经关闭；</li>
<li>经过测试，服务端已经关闭的情况下，客户端在此连接上发送数据不会触发异常，参考<a href="http://ahuaxuan.iteye.com/blog/657511">这里</a>及<a href="http://my.oschina.net/costaxu/blog/127394">这里</a>。</li>
</ul>
</blockquote>

<h3>解决方案</h3>

<p>在回收Channel时，如果连接已经关闭，则不再发送关闭请求，直接跳过。</p>

<h2>其它问题</h2>

<h3>AMQP qos（设计问题）</h3>

<p>因为Proxy的存在，后端多个结点在客户端看来像一个结点，但是basic.qos这条命令会发送到所有后端几点，这样导致客户端本来期望收到1条消息，但是实际会收到多条消息。这个导致在使用nodejs的AMQP客户端的会出现问题（nodejs客户端提供了一个不带参数的ack方法，只会ack最后一次收到的消息，可应用依赖于只收到一条消息，当收到多条消息时，就会将一条消息ack多次）。</p>

<p>但是这个问题要处理得当也比较麻烦，需要考虑各种情况下的调整：</p>

<blockquote><ul>
<li>如果qos要求是1，但后端结点数量大于1，怎么处理？如果只发送到qos到一个结点，这个结点挂了，需要如何处理？</li>
<li>如果qos比较大，可以平分到后端结点，那一个结点挂了，如何处理？调高其它结点的qos？那这个结点又恢复了，怎么处理？再把其它结点的qos调低？</li>
<li>如果遇到扩容，缩容的需求怎么处理？</li>
</ul>
</blockquote>

<p>从上面的分析可知，这个问题要处理得当，Proxy会有很复杂的逻辑，所以当前的处理是保持现状，应用的业务逻辑不应依赖于qos的变化。</p>

<h3>connection reset（代码问题）</h3>

<p>客户端SDK在运行一段时间后，会出现connection reset，查看日志后发现Proxy保存的channel数据有异常：channel在关闭时没有清除Proxy内与该channel相关的数据，而客户端又一直在打开，关闭channel，但是channel最多只能开到65535个，超过这个数量后会重新从1开始，导致使用了脏数据。</p>

<h3>RabbitMQ后端重启，Proxy重连后，无法下发数据（代码问题）</h3>

<p>本来Proxy的设计是在后端结点重启时，Proxy会重试连接。实际在更新时，却发现Proxy重连成功后，数据无法下发到客户端，但是抓包发送数据发送到Proxy。测试后发现是Proxy在做重连逻辑时，未清除某些状态，导致数据一直缓存在Proxy这一层。</p>

<h3>basic.consume没有发送到HA模式下的所有结点（代码问题）</h3>

<p>通过RabbitMQ的管理页面看到，建立到后端的连接，只有一个会消费消息，其它连接都没在干事。一开始怀疑客户端未发送正确发送basic.consume命令，后测试发现是Proxy在HA模式下的时候，只会将某些命令（queue.declare，exchange.declare等）发送到一个结点，但basic.consume需要发送到所有结点。</p>

<p><strong>[2013.11.14更新]</strong></p>

<h3>Proxy直接Crash（代码问题）</h3>

<p>前一天晚上收到报警，两台机器的Proxy都挂了，上去服务器看了下，有erl_crash.dump文件，时间差不多，一个在00:10分，一个在00:12分，把dump文件拉到本地，用CrashDumpViewer查看，看到错误信息：</p>

<blockquote><ul>
<li>no more index entries in atom_tab (max=1048576)</li>
</ul>
</blockquote>

<p>看样子像是创建了大量的atom，在CrashDumpViewer里看到大量ClientReader进程注册名的atom，但是没看到其它相应工作进程的注册名。后来反映到Proxy前面有HAProxy，是要做定期健康检查的，每次的检查都需要新建一个TCP连接，同时创建一个ClientReader进程，但是这个TCP连接会马上断开，也就是不会发送我们的期望的AMQP协议数据。看了下代码，进程注册名称的行为果然发生在进程一创建的瞬间，而不是检测到AMQP协议数据的时候，所以每次的健康检查都会导致多一个atom，前端两台HAProxy就是每次检查多出2个atom，长期运行，最终导致atom超过最大数量。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java中日志文件的读取]]></title>
    <link href="http://onlychoice.github.io/blog/2013/10/03/tailing-log-files-in-java/"/>
    <updated>2013-10-03T17:44:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/10/03/tailing-log-files-in-java</id>
    <content type="html"><![CDATA[<h2>问题</h2>

<p>应用中有时候会有读取日志文件，并做近实时分析的需求（日志监控等）。但是使用类似Log4j的日志框架，日志文件可能会滚动：老的日志文件重命名成其它文件名（比如以日期为后缀），生成一个与老文件同名的新文件，这时候就需要读取日志文件的线程能够正确区分新老文件，并读取相应更新并且不会漏读数据。当然，这个问题的前提是：日志文件本身只会append，而不会在文件中间写入或者删除。本文主要分享下解决这个问题时碰到的一些问题及解决方案。</p>

<!--more-->


<h2>问题分析</h2>

<p>首先我们来看看日志更新这件事有哪些情况可能会出现：</p>

<blockquote><ol>
<li>文件没有更新；</li>
<li>文件有更新，并且没有新的文件生成；</li>
<li>文件没有更新，并且有新的文件生成；</li>
<li>文件有更新，并且有新的文件生成；</li>
</ol>
</blockquote>

<p>也就是我们要解决两个问题：1）检测文件是否有更新，如果有更新，则读取更新；2）检测文件是否有滚动，也就是是否有新文件生成。</p>

<h3>检测更新</h3>

<p>检测更新有两种可能的方法：</p>

<blockquote><ol>
<li>通过文件更新时间：File.lastModified可以获取；</li>
<li>通过文件大小：File.length或者 FileChannel.size。</li>
</ol>
</blockquote>

<h4>文件更新时间</h4>

<p>通过文件更新时间检测更新应该是最直观的方法，但是这个方法有一个小缺陷：更新时间的精度。根据Wiki上的介绍，ext3的更新时间精度是一秒，ext4本身可以返回纳秒级别的更新时间，但是在这两种文件系统中，Java返回的都是秒级别的更新数据。这会导致什么问题呢？如果在1秒内有多次更新，那么有可能无法准确的检测到更新，如：</p>

<blockquote><p>lastmodified: 1365590117000, size: 10597</p>

<p>lastmodified: 1365590117000, size: 10610</p></blockquote>

<p>如上所示，是测试中的一个样例，文件大小已变，但是更新时间并没有变化，导致无法检测到更新。当然本身这个问题影响并不大，如果文件后续又有更新，前面的更新还是会读到的。</p>

<h4>文件大小</h4>

<p>用文件大小来判断一个文件是否有更新应该是最准确：只要文件哪怕更新一个字节，也会立即检测到文件有更新。</p>

<blockquote><ul>
<li>File.length拿到的永远是当前路径对应文件的大小，如果日志文件滚动，那么它拿到的就是新的日志文件的大小；</li>
<li>FileChannel.size则永远拿到当前channel对应物理文件的大小，即使文件滚动，老的文件被重命名，这个size拿到的还是老的文件大小。</li>
</ul>
</blockquote>

<h3>文件滚动</h3>

<p>在Linux中，inode是一个文件的唯一标识，不管文件是否重命名过。但是在Java中，却不存在这样一个接口来获取inode。在这种情况下，我们怎么来判断是否有文件生成？</p>

<blockquote><ol>
<li>通过文件大小及更新时间（忽略精度问题）：上面提到FileChannel.size可以拿到老文件的大小，如果在两次检测之间，这个大小并没有变化，并且文件更新时间有变化（通过File.lastModified获取到，拿到的可能是新文件的更新时间），则可以肯定有新文件生成；</li>
<li>通过Runtime.exec（或者ProcessBuilder），来调用shell命令“ls -i”来获取文件的inode；</li>
<li>通过JNI来获取文件的inode。</li>
</ol>
</blockquote>

<p>如果不用获取inode，就可以判断新文件是否生成，那应该是最好的了，可惜并不完美：上述第一种方案的问题是，如果老的文件有更新，并且有新的文件生成，则检测不到已经有新文件生成了。在这种情况下，如果新的文件在滚动之前又有更新，则不会丢失数据（跟lastModified的精度问题类似），否则有可能会丢失数据。在实际使用中，如果检测间隔在毫秒级，这种情况应该很少出现。</p>

<p>那通过Runtime.exec获取inode可以吗，毕竟不用写jni代码。但是实际的情况是：1）每次获取inode花费的时间平均在10毫秒以下，如果检测间隔在100毫秒，还可以接受；2）通过这种方式获取inode不稳定，测试中发现有时候获取一次inode的时间会接近1s；3）Runtime.exec是通过fork一个进程，在新进程中执行shell命令的，万一系统中已经无法创建进程，那就会阻塞我们的检测线程；4）测了一下性能，分别通过Runtime.exec及JNI获取1000次inode，JNI耗时2ms，Runtime.exec耗时8s多，JNI的方式比Runtime.exec快了4000倍。。。</p>

<h2>实现</h2>

<p>上面把问题基本已经分析清楚，那处理逻辑就比较简单下：</p>

<blockquote><ol>
<li>如果当前文件的inode与上一轮文件的inode不同，则认为有新的文件生成：如果FileChannel.size比上一轮的大，则先读取老文件更新；读取新文件的内容；</li>
<li>如果当前文件的inode与上一轮文件的inode相同，则没有新文件生成，只需要通过FileChannel.size来判断老文件是否有更新，如果有更新则读取。</li>
</ol>
</blockquote>

<h3>NativeLoader</h3>

<p>做为一个工具类，如果在使用的时候还要配置一些参数什么的，那么无疑会比较麻烦。最简单的用法应该就是把打包好的jar发布到maven，使用方只要写好依赖，直接使用就行。为此，在打包时，就预先将编译好的动态库打包进去，并且由lib本身来加载动态库。NativeLoader就是完成从jar中加载动态库的功能。</p>

<h2>总结</h2>

<p>最终代码见：<a href="https://github.com/onlychoice/log-tailer">log-tailer</a>，只支持Linux及MacOS。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java并发源码分析 - ForkJoin框架]]></title>
    <link href="http://onlychoice.github.io/blog/2013/09/17/java-concurrent-source-code-reading-3/"/>
    <updated>2013-09-17T23:04:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/09/17/java-concurrent-source-code-reading-3</id>
    <content type="html"><![CDATA[<h2>功能</h2>

<p>根据Java文档描述，ForkJoinPool中一种特殊的ExecutorService，可以执行ForkJoinTask。ForJoinTask可以在运行时Fork子任务，并join子任务的完成，本质上类似分治算法：将问题尽可能的分割，直到问题可以快速解决。对ForkJoinPool来说，与其它ExecutorService最重要的不同点是，它的工作线程会从其它工作线程的任务队列偷任务来执行。</p>

<!--more-->


<h2>实现</h2>

<p>根据代码里的文档，可以了解到ForkJoin框架主要由三个类组成：</p>

<blockquote><ul>
<li>ForkJoinPool：管理worker线程，类似ThreadPoolExecutor，提供接口用于提交或者执行任务；</li>
<li>ForkJoinWorkerThread：worker线程，任务保存在一个deque中；</li>
<li>ForkJoinTask<V>：ForkJoin框架中运行的任务，可以fork子任务，可以join子任务完成。</li>
</ul>
</blockquote>

<h3>任务队列的管理</h3>

<p>ForkJoinPool及ForkJoinWorkerThread都有维护一个任务队列，ForkJoinPool用这个队列来保存非worker线程提交的任务，而ForkJoinWorkerThread则保存提交到本worker线程的任务。</p>

<p>任务队列以deque的形式存在，不过只通过三种方式访问其中的元素：push，pop，deq，其中push和pop只会由持有该队列的线程访问，而deq操作则是否由其它worker线程来访问。对应到代码上则是：</p>

<blockquote><ul>
<li>ForkJoinTask&lt;?>[] queue：代表任务队列，环形数组；</li>
<li>int queueTop：队列头，push或者pop操作时，修改此值，因为只会被当前worker线程访问，所以是普通变量；</li>
<li>volatile int queueBase：队列尾部，deq操作时修改此值，会有多个线程访问，使用volatile。</li>
</ul>
</blockquote>

<h4>数据元素访问</h4>

<pre class="prettyprint linenums lang-java">
long u = (((s = queueTop) & (m = q.length - 1)) << ASHIFT) + ABASE;
UNSAFE.putOrderedObject(q, u, t);
queueTop = s + 1;         // or use putOrderedInt
</pre>


<p>上面的代码是从入队操作中的一段，前文提到queueTop保存队列头，那为什么不直接用queue[queueTop]=t来赋值就行了？了解原因之前，先来看看这两行代码在做什么：</p>

<pre class="prettyprint linenums lang-java">
(s = queueTop) & (m = q.length - 1) // queueTop % (q.length - 1)，也就是queueTop根据队列长度取模，
                                     // 取模后，就是队列头实际在数组中的索引；
</pre>


<p>那 Index &lt;&lt; ASHIFT + ABASE在算什么？先看看ASHIFT及ABASE的定义：</p>

<pre class="prettyprint linenums:983 lang-java">
    static {
        int s;
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class a = ForkJoinTask[].class;
            ABASE = UNSAFE.arrayBaseOffset(a);
            s = UNSAFE.arrayIndexScale(a);
        } catch (Exception e) {
            throw new Error(e);
        }
        if ((s & (s-1)) != 0)
            throw new Error("data type scale not a power of two");
        ASHIFT = 31 - Integer.numberOfLeadingZeros(s);
    }
</pre>


<p>再来看看UNSAFE.arrayBaseOffset及UNSAFE.arrayIndexScale的文档：</p>

<blockquote><p>public native int arrayBaseOffset(Class arrayClass)</p>

<p>Report the offset of the first element in the storage allocation of a
given array class.  If #arrayIndexScale  returns a non-zero value
for the same class, you may use that scale factor, together with this
base offset, to form new offsets to access elements of arrays of the
given class.</p>

<p>public native int arrayIndexScale(Class arrayClass)</p>

<p>Report the scale factor for addressing elements in the storage
allocation of a given array class.  However, arrays of &ldquo;narrow&rdquo; types
will generally not work properly with accessors like #getByte(Object, int) , so the scale > > factor for such classes is reported as zero.</p></blockquote>

<p>Java数组在实际存储时有一个对象头，后面才是实际的数组数据，而UNSAFE.arrayBaseOffset就是用来获取实际数组数据的偏移量；UNSAFE.arrayIndexScale则是获取对应数组元素占的字节数。这里的代码ABASE=16（数组对象头大小），s=4（ForkJoinTask对象引用占用字节数），ASIFT=2。</p>

<p>所以上面的Index &lt;&lt; ASHIFT + ABASE合起来就是Index左移2位=Index*4，也就是算Index的在数组中的偏移量，再加上ABASE就是Index在对象中的偏移量。也就是那一行代码主要就是算出来queueTop在队列数组中的实际偏移量，知道了这些，我们再来看第二行代码：</p>

<pre class="prettyprint linenums lang-java">
UNSAFE.putOrderedObject(q, u, t);
</pre>


<p>UNSAFE.putOrderedObject的文档：</p>

<blockquote><p>public native  void putOrderedObject(Object o,long offset, Object x)</p>

<p>Version of #putObjectVolatile(Object, long, Object)
that does not guarantee immediate visibility of the store to
other threads. This method is generally only useful if the
underlying field is a Java volatile (or if an array cell, one
hat is otherwise only accessed using volatile accesses).</p></blockquote>

<p>看的不明不白，找了下资料，<a href="http://robsjava.blogspot.com/2013/06/a-faster-volatile.html">这篇文章</a>及<a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6275329">这里</a>解释的比较清楚：</p>

<blockquote><p>Unsafe.putOrderedObject guarante that writes will not be re-orderd by instruction
reordering. Under the covers it uses the faster store-store barrier, rather than the the
slower store-load barrier, which is used when doing a volatile write.</p>

<p>write may be reordered with subsequent operations (or equivalently, might not be visible to
other threads) until some other volatile write or synchronizing action occurs)</p></blockquote>

<p>也就是说能够保证写写不会被重排序，但是不保证写会对其它线程可见，而volatile既保证写写不会被重排序，也保证写后对其它线程立即可见。可见Unsafe.putOrderedObject会比直接的volatile变量赋值速度会一点，<a href="http://robsjava.blogspot.com/2013/06/a-faster-volatile.html">这篇文章</a>则指出Unsafe.putOrderedObject会比volatile写快3倍。</p>

<p>了解清楚这两行代码的作用后，再来回答一开始提出的问题，为什么要这么用？结合代码中的文档及自己的理解，我觉得原因无非两点：</p>

<blockquote><ul>
<li>需要保证写入元素的顺序对其它worker线程一致，也就是不会产生写写重排序；</li>
<li>不需要保证写读是否重排序，因为如果其它worker线程需要从当前队列steal任务，那么首先必须得个性volatile字段
queueBase，而volatile的语义保证读之前的所有写操作的可见性，而Unsafe.putOrderedObject性能明显要好于
volatile写。</li>
</ul>
</blockquote>

<p><strong>不知道上面的理解是否正确，如有问题，请指正</strong>。</p>

<p>好吧，两行代码包含这么多的知识点。</p>

<h4>容量</h4>

<p>初始容量 1&lt;&lt;13，最大容量 1&lt;&lt;24，队列满时，以2倍的方式增长，所以容量一直是2的幂次方。下面是扩容时的代码：</p>

<pre class="prettyprint linenums:477 lang-java">
    /**
     * Creates or doubles queue array.  Transfers elements by
     * emulating steals (deqs) from old array and placing, oldest
     * first, into new array.
     */
    private void growQueue() {
        ForkJoinTask<?>[] oldQ = queue;
        int size = oldQ != null ? oldQ.length << 1 : INITIAL_QUEUE_CAPACITY;
        if (size > MAXIMUM_QUEUE_CAPACITY)
            throw new RejectedExecutionException("Queue capacity exceeded");
        if (size < INITIAL_QUEUE_CAPACITY)
            size = INITIAL_QUEUE_CAPACITY;
        ForkJoinTask<?>[] q = queue = new ForkJoinTask<?>[size];
        int mask = size - 1;
        int top = queueTop;
        int oldMask;
        if (oldQ != null && (oldMask = oldQ.length - 1) >= 0) {
            for (int b = queueBase; b != top; ++b) {
                long u = ((b & oldMask) << ASHIFT) + ABASE;
                Object x = UNSAFE.getObjectVolatile(oldQ, u);
                if (x != null && UNSAFE.compareAndSwapObject(oldQ, u, x, null))
                    UNSAFE.putObjectVolatile
                        (q, ((b & mask) << ASHIFT) + ABASE, x);
            }
        }
    }
</pre>


<p>有了开始的分析，这段代码就比较容易理解了：</p>

<blockquote><ol>
<li>从queueBase开始直到queueTop，通过UNSAFE.getObjectVolatile读取对应位置的元素；</li>
<li>通过UNSAFE.compareAndSwapObject将对应位置的元素设置为null；</li>
<li>如果上述CAS成功，则通过UNSAFE.putObjectVolatile将该元素写入到新的队列；</li>
</ol>
</blockquote>

<h4>入队</h4>

<pre class="prettyprint linenums:459 lang-java">
    final void pushTask(ForkJoinTask<?> t) {
        ForkJoinTask<?>[] q; int s, m;
        if ((q = queue) != null) {    // ignore if queue removed
            long u = (((s = queueTop) & (m = q.length - 1)) << ASHIFT) + ABASE;
            UNSAFE.putOrderedObject(q, u, t);
            queueTop = s + 1;         // or use putOrderedInt
            if ((s -= queueBase) <= 2)
                pool.signalWork();
            else if (s == m) 
                growQueue();
        }
    }
</pre>


<p>如果队列中的任务数大于2，则通知线程池唤醒或者创建一个worker线程；如果队列已经满了（s == m），则通过growQueue对队列进行扩容。</p>

<h4>出队</h4>

<p>出队分两种，一种从队列头部出队（当前worker线程），别一种从队列尾部出队（其它worker线程）。</p>

<p><strong>从队列头部出队：</strong></p>

<pre class="prettyprint linenums:546 lang-java">
    private ForkJoinTask<?> popTask() {
        int m;
        ForkJoinTask<?>[] q = queue;
        if (q != null && (m = q.length - 1) >= 0) {
            for (int s; (s = queueTop) != queueBase;) {
                int i = m & --s;
                long u = (i << ASHIFT) + ABASE; // raw offset
                ForkJoinTask<?> t = q[i];
                if (t == null)   // lost to stealer
                    break;
                if (UNSAFE.compareAndSwapObject(q, u, t, null)) {
                    queueTop = s; // or putOrderedInt
                    return t;
                }
            }
        }
        return null;
    }
</pre>


<p>主要逻辑如下：</p>

<blockquote><ol>
<li>在队列不为空的情况下，从queueTop &ndash; 1位置处读取元素；</li>
<li>如果元素不为null，则通过UNSAFE.compareAndSwapObject将queueBase对应的元素置为null；</li>
<li>如果上述CAS成功，将该元素返回，并将queueTop减1；如果CAS失败，则重试。</li>
</ol>
</blockquote>

<p><strong>从队列尾部出队：</strong></p>

<pre class="prettyprint linenums:506 lang-java">
    final ForkJoinTask<?> deqTask() {
        ForkJoinTask<?> t; ForkJoinTask<?>[] q; int b, i;
        if (queueTop != (b = queueBase) &&
            (q = queue) != null && // must read q after b
            (i = (q.length - 1) & b) >= 0 &&
            (t = q[i]) != null && queueBase == b &&
            UNSAFE.compareAndSwapObject(q, (i << ASHIFT) + ABASE, t, null)) {
            queueBase = b + 1;
            return t;
        }
        return null;
    }
</pre>


<p>主要逻辑如下：</p>

<blockquote><ol>
<li>在队列不为空，并且queueBase对应位置的元素不为null，从queueBase读取元素；</li>
<li>通过UNSAFE.compareAndSwapObject将queueBase对应的元素置为null；</li>
<li>如果上述CAS成功，将queueBase位置对应的元素返回，并将queueBase加1。</li>
</ol>
</blockquote>

<h3>提交任务</h3>

<p>ForkJoinPool提供了类似ThreadPoolExecutor的接口来提供普通任务或者ForkJoinTask，这些接口最终都会调用forkOrSubmit来完成任务提交：</p>

<pre class="prettyprint linenums:1529 lang-java">
    private <T> void forkOrSubmit(ForkJoinTask<T> task) {
        ForkJoinWorkerThread w;
        Thread t = Thread.currentThread();
        if (shutdown)
            throw new RejectedExecutionException();
        if ((t instanceof ForkJoinWorkerThread) &&
            (w = (ForkJoinWorkerThread)t).pool == this)
            w.pushTask(task);
        else
            addSubmission(task);
    }
</pre>


<p>可以看到，forkOrSubmit要么将任务提交到对应worker线程的任务队列（提交任务的线程本身就是worker线程，并且该worker线程属于当前ForkJoinPool，通过w.pushTask提交任务，前文已分析过），要么将任务提交到ForkJoinPool提供的任务队列。</p>

<p>看一下addSubmission的实现：</p>

<pre class="prettyprint linenums:1529 lang-java">
    private void addSubmission(ForkJoinTask<?> t) {
        final ReentrantLock lock = this.submissionLock;
        lock.lock();
        try {
            ForkJoinTask<?>[] q; int s, m;
            if ((q = submissionQueue) != null) {    // ignore if queue removed
                long u = (((s = queueTop) & (m = q.length-1)) << ASHIFT)+ABASE;
                UNSAFE.putOrderedObject(q, u, t);
                queueTop = s + 1;
                if (s - queueBase == m)
                    growSubmissionQueue();
            }
        } finally {
            lock.unlock();
        }
        signalWork();
    }
</pre>


<p>基本逻辑跟pushTask一致，只不过多加了个锁（同一时间，可能会有多个外部线程提交任务），并且是每加一个任务就会调用singalWork。</p>

<h3>fork子任务</h3>

<p>也就是当前任务fork一个子任务，看一下实现：</p>

<pre class="prettyprint linenums:621 lang-java">
    public final ForkJoinTask<V> fork() {
        ((ForkJoinWorkerThread) Thread.currentThread())
            .pushTask(this);
        return this;
    }
</pre>


<p>比较简单，就是将任务提交到当前worker线程的任务队列。</p>

<h3>join子任务</h3>

<p>等待子任务的完成：</p>

<pre class="prettyprint linenums:638 lang-java">
    public final V join() {
        if (doJoin() != NORMAL)
            return reportResult();
        else
            return getRawResult();
    }
</pre>




<pre class="prettyprint linenums:348 lang-java">
    private int doJoin() {
        Thread t; ForkJoinWorkerThread w; int s; boolean completed;
        if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) {
            if ((s = status) < 0)
                return s;
            if ((w = (ForkJoinWorkerThread)t).unpushTask(this)) {
                /**
                 * unpushTask与上面分析的popTask实现类似，只是多了个判断，队列头的任务是不是当前任务。
                 * 也就是说，当join任务时，如果当前任务就在队列头部，就直接在当前worker线程执行。
                 */
                try {
                    completed = exec();
                } catch (Throwable rex) {
                    return setExceptionalCompletion(rex);
                }
                if (completed)
                    return setCompletion(NORMAL);
            }
            
            /**
             * 任务不在队列头部，调用joinTask等待任务完成。
             */
            return w.joinTask(this);
        }
        else
            /**
             * 不是worker线程，直接调用Object.wait等待任务完成。
             */
            return externalAwaitDone();
    }
</pre>


<p>我们来看一下joinTask的实现：</p>

<pre class="prettyprint linenums:708 lang-java">
    final int joinTask(ForkJoinTask<?> joinMe) {
        ForkJoinTask<?> prevJoin = currentJoin;
        currentJoin = joinMe;
        for (int s, retries = MAX_HELP;;) {
            if ((s = joinMe.status) < 0) {
                currentJoin = prevJoin;
                return s;
            }
            if (retries > 0) {
                if (queueTop != queueBase) {
                    if (!localHelpJoinTask(joinMe))
                        retries = 0;           // cannot help
                }
                else if (retries == MAX_HELP >>> 1) {
                    --retries;                 // check uncommon case
                    if (tryDeqAndExec(joinMe) >= 0)
                        Thread.yield();        // for politeness
                }
                else
                    retries = helpJoinTask(joinMe) ? MAX_HELP : retries - 1;
            }
            else {
                retries = MAX_HELP;           // restart if not done
                pool.tryAwaitJoin(joinMe);
            }
        }
    }
</pre>


<p>主要流程：</p>

<blockquote><ol>
<li>localHelpJoinTask：如果当前工作线程的任务队列不为空，则尝试在当前线程执行一个任务（未必是要join的任务）；但是如果任务队列的头部已经有一个任务在等待任务完成，则通过Object.wait等待任务完成；</li>
<li>tryDeqAndExec：如果要join的任务在某个工作线程任务队列的尾部，则直接把任务偷取过来并执行；</li>
<li>helpJoinTask：找到偷取当前任务的工作线程，并从其队列尾部偷取一个任务执行；如果该工作线程也在等待一个任务完成，则继续递归寻找偷取该任务的工作线程。</li>
</ol>
</blockquote>

<h3>偷取任务</h3>

<p>偷取任务的逻辑很简单，就是从其它工作线程的队列尾部（queueBase）出队一个任务，并在当前工作线程中执行。可以看一下helpJoinTask中的一段代码：</p>

<pre class="prettyprint linenums:806 lang-java">
    if (t != null && v.queueBase == b &&
        UNSAFE.compareAndSwapObject(q, u, t, null)) { // 获取到队列尾部的任务，通过CAS将队列中对应位置设为null
        v.queueBase = b + 1; // 更新queueBase
        v.stealHint = poolIndex; // 将stealHint设为当前工作线程
        ForkJoinTask<?> ps = currentSteal;
        currentSteal = t;
        t.doExec(); // 在当前工作线程中执行偷取到的任务
        currentSteal = ps;
        helped = true;
    }
</pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java并发源码分析 - ThreadPoolExecutor]]></title>
    <link href="http://onlychoice.github.io/blog/2013/09/13/java-concurrent-source-code-reading-2/"/>
    <updated>2013-09-13T14:32:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/09/13/java-concurrent-source-code-reading-2</id>
    <content type="html"><![CDATA[<h2>为什么需要线程池？</h2>

<blockquote><ol>
<li>避免在运行大量任务时，频繁的线程创建和销毁开销；</li>
<li>使资源的使用得到有效控制，避免创建过多的线程占用系统资源。</li>
</ol>
</blockquote>

<!--more-->


<h2>基本概念</h2>

<h3>Core and maximum pool sizes</h3>

<p>控制线程池核心线程数以及最大可生成的线程数量。是否需要创建线程与当前线程的数量以及任务队列的状态在关，后面会详述。</p>

<h3 id="timeout">Keep-alive times</h3>


<p>默认情况下，只有在当前worker线程数大于core大小的情况下，空闲一定时间的worker线程才可以被回收，但是也可以通过allowCoreThreadTimeOut(boolean)函数来控制core线程的超时时间。</p>

<h3>任务队列</h3>

<p>ThreadPoolExecutor使用BlockingQueue来管理任务队列，任务队列与线程池大小的关系如下：</p>

<blockquote><ul>
<li>如果线程池数量小于corePoolSize，Executor倾向于新增worker线程；</li>
<li>如果线程池数量多于或者等于corePoolSize倾向于将任务放入队列；</li>
<li>如果任务队列已满，并且线程池数量还没有超过maximumPoolSize，那么新的worker线程；</li>
<li>如果任务队列已满，并且线程池数量已经超过maximumPoolSize，那么任务被reject；</li>
</ul>
</blockquote>

<h2>实现</h2>

<h3>提交任务</h3>

<pre class="prettyprint linenums:1300 lang-java">
    public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();

        int c = ctl.get();
        if (workerCountOf(c) < corePoolSize) {
            /**
             * 如果当前worker数量小于corePoolSize，则创建新的worker。
             */
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        
        /**
         * 尝试将任务添加到任务队列。
         */
        if (isRunning(c) && workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) && remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        /**
         * 在worker数量大于corePoolSize，并且任务添加到队列失败（队列满）的情况下，尝试创建新的worker，
         * 如果创建失败表示已经达到maximumPoolSize，则reject任务。
         */
        else if (!addWorker(command, false))
            reject(command);
    }
</pre>


<h3>创建worker线程</h3>

<p>去除一些状态检查后，核心代码如下：</p>

<pre class="prettyprint linenums:886 lang-java">
    private boolean addWorker(Runnable firstTask, boolean core) {
        Worker w = new Worker(firstTask);
        Thread t = w.thread;

        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            workers.add(w);

            int s = workers.size();
            if (s > largestPoolSize)
                largestPoolSize = s;
        } finally {
            mainLock.unlock();
        }

        t.start();

        return true;
    }
</pre>


<p>可以看到，很简单，创建一个Worker线程，将他加到workers集合中，然后启动对应worker线程，DONE。</p>

<p>我们来看看Worker的定义：</p>

<pre class="prettyprint linenums:575 lang-java">
    private final class Worker
        extends AbstractQueuedSynchronizer
        implements Runnable
    {
        /**
         * This class will never be serialized, but we provide a
         * serialVersionUID to suppress a javac warning.
         */
        private static final long serialVersionUID = 6138294804551838833L;

        /** Thread this worker is running in.  Null if factory fails. */
        final Thread thread;
        /** Initial task to run.  Possibly null. */
        Runnable firstTask;
        /** Per-thread task counter */
        volatile long completedTasks;

        /**
         * Creates with given first task and thread from ThreadFactory.
         * @param firstTask the first task (null if none)
         */
        Worker(Runnable firstTask) {
            this.firstTask = firstTask;
            this.thread = getThreadFactory().newThread(this);
        }

        /** Delegates main run loop to outer runWorker  */
        public void run() {
            runWorker(this);
        }

        // Lock methods
        //
        // The value 0 represents the unlocked state.
        // The value 1 represents the locked state.

        protected boolean isHeldExclusively() {
            return getState() == 1;
        }

        protected boolean tryAcquire(int unused) {
            if (compareAndSetState(0, 1)) {
                setExclusiveOwnerThread(Thread.currentThread());
                return true;
            }
            return false;
        }

        protected boolean tryRelease(int unused) {
            setExclusiveOwnerThread(null);
            setState(0);
            return true;
        }

        public void lock()        { acquire(1); }
        public boolean tryLock()  { return tryAcquire(1); }
        public void unlock()      { release(1); }
        public boolean isLocked() { return isHeldExclusively(); }
    }
</pre>


<p>除去跟锁定义相关的代码后，核心就是run函数的实现：调用runWorker运行Worker线程的运行逻辑。</p>

<h3>Worker线程运行逻辑</h3>

<pre class="prettyprint linenums:1098 lang-java">
    final void runWorker(Worker w) {
        Runnable task = w.firstTask;
        w.firstTask = null;
        boolean completedAbruptly = true;
        try {
            while (task != null || (task = getTask()) != null) {
                w.lock();
                clearInterruptsForTaskRun();
                try {
                    beforeExecute(w.thread, task);
                    Throwable thrown = null;
                    try {
                        task.run();
                    } catch (RuntimeException x) {
                        thrown = x; throw x;
                    } catch (Error x) {
                        thrown = x; throw x;
                    } catch (Throwable x) {
                        thrown = x; throw new Error(x);
                    } finally {
                        afterExecute(task, thrown);
                    }
                } finally {
                    task = null;
                    w.completedTasks++;
                    w.unlock();
                }
            }
            completedAbruptly = false;
        } finally {
            processWorkerExit(w, completedAbruptly);
        }
    }
</pre>


<p>就是一个while循环，在有任务的情况下（两种：一种在创建Worker线程时传入，由firtstTask传入；一种通过getTask由任务队列获取），执行任务，并调用设置的回调函数（beforeExecute，afterExecute等）。</p>

<p>我们来看看getTask的实现：</p>

<pre class="prettyprint linenums:1098 lang-java">
    private Runnable getTask() {
        boolean timedOut = false; // Did the last poll() time out?
        for (;;) {
            try {
                Runnable r = timed ?
                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                    workQueue.take();
                if (r != null)
                    return r;
                timedOut = true;
            } catch (InterruptedException retry) {
                timedOut = false;
            }
        }
    }
</pre>


<p>去除了状态检查的相关代码后，核心的逻辑如下：在需要处理<a href="#timeout">超时</a>的情况下调用BlockingQueue.poll来获取任务，如果在超时后还没有任务，则让相应的worker线程退出；如果不需要处理超时时候，调用BlockingQueue.take，阻塞当前worker线程一直到有任务到达。</p>

<h3>总结</h3>

<p>ThreadPoolExecutor会根据线程池状态和任务队列状态创建worker线程，而每个worker线程的主要任务就是不断的去任务队列里去拿任务：要么一直阻塞等，要么超时后退出；拿到任务后，运行任务并调用相关回调。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java并发源码分析 - 锁]]></title>
    <link href="http://onlychoice.github.io/blog/2013/08/31/java-concurrent-source-code-reading-1/"/>
    <updated>2013-08-31T16:07:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/08/31/java-concurrent-source-code-reading-1</id>
    <content type="html"><![CDATA[<p>（注：文章里涉及到的代码分析，基于jdk1.7.0_10 Hotspot 64-Bit）</p>

<h2>基本概念</h2>

<p>Java同步机制除了内置的synchronized（包含Object.wait/notify）以外，还通过concurrent包提供了多种锁，包含ReentrantLock、Semaphore、ReentrantReadWriteLock等，以及跟Object.wait/notify类似语义的Condition接口。</p>

<!--more-->


<h4>接口定义</h4>

<p>具体的接口（Lock，Condition）就不在这里赘述，只做个简单总结：</p>

<blockquote><ol>
<li>Lock接口提供三种不同类型的获取锁接口：不响应中断（interrupt）、响应中断、可以设置超时；</li>
<li>Condition接口提供类似Object.wait语义的四种await接口：不响应中断（interrupt）、响应中断、可以设置超时、可以设置deadline；不管哪一种await，都必须在调用前持有跟该Condition对象关联的锁，Condition的实现会保证await调用在进入阻塞状态前释放锁，并且在await调用返回时，重新持有锁。</li>
</ol>
</blockquote>

<h4>锁类型</h4>

<blockquote><ol>
<li>同synchronized一样，concurrent包里提供的锁都是可重入的（reentrant）：一个线程在持有一个锁时，在不释放该锁的前提下，可多次重新持有该锁；</li>
<li>互斥锁和共享锁：在一个线程持有锁的时候，如果其它线程不能再持有该锁，则为互斥锁，否则为共享锁；concurrent包里的ReentrantLock为互斥锁，Semaphore为共享锁，ReentrantReadWriteLock是共享锁及互斥锁的结合；</li>
<li>公平锁和非公平锁：公平锁保证线程以FIFO的顺序持有锁（不包含tryLock接口），但非公平锁不保证这点：在有线程在排队等待获取当前锁的时候，新的线程可以直接竞争成功并持有锁；</li>
</ol>
</blockquote>

<h2>基本框架</h2>

<p>简单查看一下ReetrantLock、Semaphore等类的实现，会发现都依赖于AbstractQueuedSynchronizer（AQS）这个类，这个其实是concurrent包里实现同步机制的一个核心框架，可以通过这篇<a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf" title="The java.util.concurrent Synchronizer Framework">论文</a>来了解这个框架。该框架的核心实现要素包含以下三点：</p>

<blockquote><ol>
<li>同步状态的原子性管理</li>
<li>等待队列的管理</li>
<li>线程的阻塞和唤醒</li>
</ol>
</blockquote>

<h4>同步状态的原子性管理</h4>

<p>AQS将状态定义为一个整型变量（volatile int state），对它的修改AQS提供了两个接口，一个是基于volatile语义：</p>

<pre class="prettyprint linenums:549 lang-java">
    protected final void setState(int newState) {
        state = newState;
    }
</pre>


<p>另外一个依赖于Unsafe.compareAndSwapInt：</p>

<pre class="prettyprint linenums:564 lang-java">
    protected final boolean compareAndSetState(int expect, int update) {
        // See below for intrinsics setup to support this
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
    }
</pre>


<p>那什么时候用setState，什么时候用compareAndSetState呢？简单看了下调用关系，有如下特征：</p>

<blockquote><ul>
<li>初始化state时一般用setState，比如：Semaphore、CountDownLatch、ReentrantReadWriteLock等的AQS子类初始化；</li>
<li>互斥锁的可重入处理逻辑中一般调用setState，比如：ReentrantLock的tryAcquire，ReentrantReadWriteLock的tryAcquire；</li>
<li>互斥锁的释放锁操作一般调用setState，比如：ReentrantLock的tryRelease，ReentrantReadWriteLock的tryRelease；</li>
<li>其它情况下都调用compareAndSetState。</li>
</ul>
</blockquote>

<p>从以上的情况来看，应该是在基本无竞争（初始化，重入处理、互斥锁的释放）的情况下调用setState；竞争比较激烈的情况下调用compareAndSetState。</p>

<h4>等待队列的管理</h4>

<p>AQS使用CLH队列的变种来管理等待线程，每个等待线程为一个结点（AbstractQueuedSynchronizer.Node），后文会混用结点和线程。</p>

<p>CLH队列中结点之间并不存在实际的连接，后继结点在等待锁的时候只是在前续结点的状态字段上自旋，直到获取锁。<a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf" title="The java.util.concurrent Synchronizer Framework">论文</a>对AQS使用prev及next字段的解释是：</p>

<blockquote><ol>
<li>prev主要为了完成超时及取消语义：如果前继结点取消，那么就是向前找到一个未取消的前继结点；</li>
<li>next的主要作用在于优化后继结点的查找，避免每次都需要从tail结点向前反向查找。</li>
</ol>
</blockquote>

<h4>线程的阻塞和唤醒</h4>

<p>依赖于LockSupport.park（阻塞当前线程，实际调用Unsafe.park）及LockSupport.unpark（唤醒指定线程，实际调用Unsafe.unpark）；根据LockSupport的Java doc可以了解到以下内容：</p>

<blockquote><ul>
<li>park与unpark使用类似Semaphore的许可机制，如果当前线程拥有许可，那个park会消费掉该许可，并立即返回；如果当前线程没有许可，则当前线程会阻塞；unpark会导致指定线程的许可可用；</li>
<li>许可不会累加，最多只有一个，也就是说连续多次的unpark并不会导致许可变多，也就是说如下<a href="http://whitesock.iteye.com/blog/1336409" title="Inside AbstractQueuedSynchronizer (1)">代码</a>还是会导致当前线程阻塞：</li>
</ul>
</blockquote>

<pre class="prettyprint linenums lang-java">
LockSupport.unpark(Thread.currentThread());  
LockSupport.unpark(Thread.currentThread());  
LockSupport.park();  
LockSupport.park();  
</pre>


<blockquote><ul>
<li>关于park()和park(Object blocker)的区别，Object blocker参数的作用在于允许记录当前线程被阻塞的原因，以便监控分析工具进行分析。官方的文档中也更建议使用park(Object blocker)。</li>
</ul>
</blockquote>

<h3>AQS实现</h3>

<p>分析AQS之前先了解下concurrent包里的类是如何使用AQS的。AQS是抽象类，ReentrantLock、Semaphore等类会在使用时定义一个子类（Sync，一般还会根据是否是公平锁定义FireSync、NonfairSync），根据具体的需要重写AQS定义的四个protected接口：</p>

<pre class="prettyprint linenums lang-java">
/**
 * 用于互斥锁。
 */
protected boolean tryAcquire(int arg);
protected boolean tryRelease(int arg);

/**
 * 用于共享锁。
 */
protected int tryAcquireShared(int arg);
protected boolean tryReleaseShared(int arg);
</pre>


<p>注意返回值上，只有tryAcquireShared的返回值为int：大于0时，代表当前获取锁成功，后续的获取锁请求也可能会成功；等于0时，代表当前获取锁成功，后续获取锁请求必须等待；小于0时，代表当前获取锁失败，必须等待；其它返回值都为boolean，true则成功，false失败。</p>

<p>上述这几个接口的主要作用是什么呢？将管理锁（或者其它实现）的状态的任务交给具体实现类，这样AQS就不需要知道各个不同锁机制的状态之间的差别，从而简化AQS的实现。</p>

<p>然后具体的锁实现会调用AQS定义的几个公有方法来获取或者释放锁：</p>

<pre class="prettyprint linenums lang-java">
/**
 * 用于互斥锁：分别对应不响应中断、响应中断、可设置超时的获取锁接口.
 */
public final void acquire(int arg);
public final void acquireInterruptibly(int arg) throws InterruptedException;
public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException;
public final boolean release(int arg);

/**
 * 用于共享锁：分别对应不响应中断、响应中断、可设置超时的获取锁接口.
 */
public final void acquireShared(int arg);
public final void acquireSharedInterruptibly(int arg) throws InterruptedException;
public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException;
public final boolean releaseShared(int arg);
</pre>


<h4>addWaiter：等待队列的加入</h4>

<pre class="prettyprint linenums:605 lang-java">
    private Node addWaiter(Node mode) {
        Node node = new Node(Thread.currentThread(), mode);
        // Try the fast path of enq; backup to full enq on failure
        Node pred = tail;
        if (pred != null) {
            /**
             * 通过CAS来更改队列tail结点。             
             * 注意：在并发访问时，这里的CAS成功，可以保证prev结点非null，但next结点有可能为null。
             */
            node.prev = pred;
            if (compareAndSetTail(pred, node)) {
                pred.next = node;
                return node;
            }
        }
        enq(node);
        return node;
    }
</pre>




<pre class="prettyprint linenums:605 lang-java">
    private Node enq(final Node node) {
        for (;;) {
            Node t = tail;
            if (t == null) { // Must initialize
                 /**
                  * 这里多了个初始化：也就是有需要时才初始化head结点。
                  */
                if (compareAndSetHead(new Node()))
                    tail = head;
            } else {
                /**
                 * 通过CAS来更改队列tail结点。
                 * 注意：在并发访问时，这里的CAS成功，可以保证prev结点非null，但next结点有可能为null。
                 */
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                    t.next = node;
                    return t;
                }
            }
        }
    }
</pre>


<p>从上面的代码可以知道，结点的加入只是简单的通过CAS更新队列的tail字段：保证prev跟tail的原子更新，但不保证tail与next的原子更新。</p>

<h4>acquire：互斥锁获取</h4>

<pre class="prettyprint linenums:1196 lang-java">
    public final void acquire(int arg) {
        /*
         * 调用具体实现类的tryAcquire，如果返回true，则认为获取锁成功，当前函数返回；
         * 如果返回false，则将当前线程加入锁的等待队列（addWaiter，并且注意这里的加的
         * 等待结点类型为Node.EXCLUSIVE，也就是互斥锁），当前线程会进入休眠（dormant）
         * 状态，并等待前继结点唤醒，然后重新竞争锁，直到获取锁后返回。
         *
         * acquireQueued返回true说明线程在等待过程中被中断过（interrupted），则通过
         * selfInterrupt（实际调用Thread.currentThread().interrupt()）重新
         * interrupte当前线程以向调用者传递中断信号。
         */
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
</pre>




<pre class="prettyprint linenums:855 lang-java">
    final boolean acquireQueued(final Node node, int arg) {
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head && tryAcquire(arg)) {
                     /**
                      * 只有在当前结点的前继结点为head时，当前结点去才会尝试获取锁。
                      * 获取锁成功时（tryAcquire返回true），将当前结点设置成head，
                      * 并根据中断状态返回true或者false。
                      */
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return interrupted;
                }
                
                /**
                 * shouldParkAfterFailedAcquire判断是否应该阻塞（park）当前线程，判断的依据是
                 * 前继结点的状态（p.waitStatus），只有该状态为Node.SIGNAL时才会阻塞当前线程：
                 * 此状态说明，当前结点无法暂时获取锁，并且前继结点保证会在释放锁的时候唤醒当前线程。
                 *
                 * parkAndCheckInterrupt的实现就比较简单了，调用LockSupport.park(this)阻塞
                 * 当前线程，并返回线程当前的中断状态。
                 */
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</pre>


<h4>release：互斥锁的释放</h4>

<pre class="prettyprint linenums:1259 lang-java">
    public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null && h.waitStatus != 0)
                /**
                 * 在head不为null，并且waitStatus不为0的情况下，唤醒后继结点：只是给后续结点一次
                 * 竞争锁的机会，后续结点未必能获取到锁。 
                 *
                 * unparkSuccessor的实现：找到h的后继结点，并调用LockSupport.unpark唤醒后继结点
                 * 对应的线程。
                 */
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
</pre>


<h4>acquireShared：共享锁获取</h4>

<pre class="prettyprint linenums:946 lang-java">
    public final void acquireShared(int arg) {
        /**
         * 调用具体实现类的tryAcquireShared，如果返回值不小于0，则认为获取共享锁成功；
         * 否则通过doAcquireShared调用进入等待锁逻辑。
         */
        if (tryAcquireShared(arg) < 0)
            doAcquireShared(arg);
    }
</pre>




<pre class="prettyprint linenums:946 lang-java">
    private void doAcquireShared(int arg) {
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r >= 0) {
                        /**
                         * 仔细与上面的互斥锁的获取逻辑比较下，会发现逻辑基本差不多：
                         * 前继结点为head，并且获取锁成功（与互斥锁不同的时tryAcquireShared返回值
                         * 不小于0时，认为获取锁成功）；不但要将当前结点设置为head结点，并且要将此事件
                         * 向后传递（setHeadAndPropagate）。
                         */
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        if (interrupted)
                            selfInterrupt();
                        failed = false;
                        return;
                    }
                }
                
                /**
                 * 与互斥锁逻辑一致
                 */
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</pre>




<pre class="prettyprint linenums:708 lang-java">
    private void setHeadAndPropagate(Node node, int propagate) {
        Node h = head; // Record old head for check below
        setHead(node);
        /*
         * Try to signal next queued node if:
         *   Propagation was indicated by caller,
         *     or was recorded (as h.waitStatus) by a previous operation
         *     (note: this uses sign-check of waitStatus because
         *      PROPAGATE status may transition to SIGNAL.)
         * and
         *   The next node is waiting in shared mode,
         *     or we don't know, because it appears null
         *
         * The conservatism in both of these checks may cause
         * unnecessary wake-ups, but only when there are multiple
         * racing acquires/releases, so most need signals now or soon
         * anyway.
         */
        if (propagate > 0 || h == null || h.waitStatus < 0) {
            Node s = node.next;
            if (s == null || s.isShared())
                doReleaseShared();
        }
    }
</pre>


<p>setHeadAndPropagate除了将head设置为当前持有锁的结点外，还需要保证在后面这两种情况下向后传播可以获取锁的信息：</p>

<blockquote><ol>
<li>propagate > 0（也就是tryAcquireShared > 0，表示后续的获取锁操作也可能成功）；</li>
<li>原始head结点的waitStatus &lt; 0，也就是以前有某个结点希望释放锁的操作向后传播。</li>
</ol>
</blockquote>

<h4>releaseShared：共享锁的释放</h4>

<pre class="prettyprint linenums:1339 lang-java">
    public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {
            doReleaseShared();
            return true;
        }
        return false;
    }
</pre>




<pre class="prettyprint linenums:670 lang-java">
    private void doReleaseShared() {
        for (;;) {
            Node h = head;
            if (h != null && h != tail) {
                int ws = h.waitStatus;
                if (ws == Node.SIGNAL) {
                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                        continue;            // loop to recheck cases
                    unparkSuccessor(h);
                }
                else if (ws == 0 &&
                         !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                    continue;                // loop on failed CAS
            }
            if (h == head)                   // loop if head changed
                break;
        }
    }
</pre>


<p>可以看到，doReleaseShared需要保证两点：</p>

<blockquote><ol>
<li>要么至少唤醒一个等待的结点：waitStatus == Node.SIGNAL；</li>
<li>要么将当前head结点的waitStatus设置成Node.PROPAGATE，以保证在后续线程持有到锁后，可以向后传播此次释放锁事件（见setHeadAndPropagate的分析）。</li>
</ol>
</blockquote>

<h2>具体锁实现</h2>

<h3>ReentrantLock</h3>

<p>互斥模式，state代表互斥锁的状态：为0说明当前锁可用；为1说明当前锁已经被某个线程持有，其它线程必须等待。获取锁等价于将state设置成1；释放锁等价于将state设置为0。</p>

<h4>公平锁获取</h4>

<pre class="prettyprint linenums:236 lang-java">
        protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (!hasQueuedPredecessors() &&
                    compareAndSetState(0, acquires)) {
                    /**
                     * 只有在等待队列里没有前继等待线程时（!hasQueuedPredecessors），
                     * 当前线程才能尝试获取锁（更新锁状态：compareAndSetState(0, acquires)），
                     * 如果成功则将当前线程标记为锁持有者，并且返回true。
                     */
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                /**
                 * 处理重入逻辑：当前线程持有锁，并且又发起获取锁请求
                 */
                int nextc = c + acquires;
                if (nextc < 0)
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
</pre>


<h4>非公平锁获取</h4>

<pre class="prettyprint linenums:217 lang-java">
        protected final boolean tryAcquire(int acquires) {
            return nonfairTryAcquire(acquires);
        }
</pre>




<pre class="prettyprint linenums:133 lang-java">
        final boolean nonfairTryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                /**
                 * 跟公平锁获取相比，这里没有判断是否有前继等待线程。也就是说当前线程可以在等待队列里
                 * 有线程在等待获取锁的时候，竞争成功并且持有锁，这对其它等待线程来说，就是不公平的。
                 */
                if (compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0) // overflow
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
</pre>


<h3>ReentrantReadWriteLock</h3>

<p>共享互斥模式结合：写锁对应互斥锁，读锁对应共享锁。state被分为两部分：高16位代表读锁持有数量；低16位代表写锁持有数量。</p>

<p>主要的实现逻辑跟ReentrantLock类似，但因为同时有两个锁，所以有些不同：</p>

<blockquote><ol>
<li>在写锁被当前线程持有的情况下，其它线程不同持有任意锁；</li>
<li>在写锁被当前线程持有的情况下，当前线程可以继续请求获取读锁和写锁；</li>
<li>在读锁被当前线程持有的情况下，其它线程可以持有读锁，不能持有写锁；</li>
<li>在读锁被当前线程持有的情况下，当前线程和其它持有读锁的线程可以继续请求获取读锁，不能请求获取写锁。</li>
</ol>
</blockquote>

<p>代码就不详细说明了。</p>

<h3>Semaphore</h3>

<p>共享模式，state代表许可的个数，初始为许可的个数，每一次的acquire，许可减1。注意：tryAcquireShared返回为int，这里会返回剩余的许可个数。</p>

<p>公平与非公平的处理与ReentrantLock处理逻辑类似，不再详细分析。</p>

<h3>CountDownLatch</h3>

<p>共享模式，state代表count个数，初始为count个数。下面为核心代码：</p>

<pre class="prettyprint linenums:177 lang-java">
        protected int tryAcquireShared(int acquires) {
            return (getState() == 0) ? 1 : -1;
        }

        protected boolean tryReleaseShared(int releases) {
            // Decrement count; signal when transition to zero
            for (;;) {
                int c = getState();
                if (c == 0)
                    return false;
                int nextc = c-1;
                if (compareAndSetState(c, nextc))
                    return nextc == 0;
            }
        }
</pre>


<p>可以看到，在初始情况下，所有的tryAcquireShared（CountDownLatch.await会调用此方法）都会阻塞（getState == count，不为0）；每一次的tryReleaseShared（CountDownLatch.countDown会调用此方法）将count减1，直到为0并且会返回true（nextc == 0），这时acquireShared会调用doReleaseShared唤醒被阻塞的线程（getState == 0保证tryAcquireShared肯定会成功）。</p>

<h3>FutureTask</h3>

<p>共享模式，state代表任务的完成状态：0代表任务已经准备就绪，1代表任务正在运行，2代表任务已经完成，4代表任务取消。</p>

<pre class="prettyprint linenums:223 lang-java">
        /**
         * Implements AQS base acquire to succeed if ran or cancelled
         */
        protected int tryAcquireShared(int ignore) {
            return innerIsDone() ? 1 : -1;
        }

        /**
         * Implements AQS base release to always signal after setting
         * final done status by nulling runner thread.
         */
        protected boolean tryReleaseShared(int ignore) {
            runner = null;
            return true;
        }
</pre>


<p>由上面代码可以看到在任务没有完成时，任何调用tryAcquireShared（FutureTask.get会调用此方法）的线程都会阻塞；tryReleaseShared永远返回true。</p>

<p>任务执行完成后，会将state设置成2（正常完成或者出现异常）或者4（任务被取消）：innerIsDone方法在这两种情况下都会返回true。</p>
]]></content>
  </entry>
  
</feed>
