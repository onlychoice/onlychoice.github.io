<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: concurrent | SHOW ME THE CODE]]></title>
  <link href="http://onlychoice.github.io/blog/categories/concurrent/atom.xml" rel="self"/>
  <link href="http://onlychoice.github.io/"/>
  <updated>2013-11-16T23:09:55+08:00</updated>
  <id>http://onlychoice.github.io/</id>
  <author>
    <name><![CDATA[Zhihui Jiao]]></name>
    <email><![CDATA[jzhihui521@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Java并发源码分析 - ForkJoin框架]]></title>
    <link href="http://onlychoice.github.io/blog/2013/09/17/java-concurrent-source-code-reading-3/"/>
    <updated>2013-09-17T23:04:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/09/17/java-concurrent-source-code-reading-3</id>
    <content type="html"><![CDATA[<h2>功能</h2>

<p>根据Java文档描述，ForkJoinPool中一种特殊的ExecutorService，可以执行ForkJoinTask。ForJoinTask可以在运行时Fork子任务，并join子任务的完成，本质上类似分治算法：将问题尽可能的分割，直到问题可以快速解决。对ForkJoinPool来说，与其它ExecutorService最重要的不同点是，它的工作线程会从其它工作线程的任务队列偷任务来执行。</p>

<!--more-->


<h2>实现</h2>

<p>根据代码里的文档，可以了解到ForkJoin框架主要由三个类组成：</p>

<blockquote><ul>
<li>ForkJoinPool：管理worker线程，类似ThreadPoolExecutor，提供接口用于提交或者执行任务；</li>
<li>ForkJoinWorkerThread：worker线程，任务保存在一个deque中；</li>
<li>ForkJoinTask<V>：ForkJoin框架中运行的任务，可以fork子任务，可以join子任务完成。</li>
</ul>
</blockquote>

<h3>任务队列的管理</h3>

<p>ForkJoinPool及ForkJoinWorkerThread都有维护一个任务队列，ForkJoinPool用这个队列来保存非worker线程提交的任务，而ForkJoinWorkerThread则保存提交到本worker线程的任务。</p>

<p>任务队列以deque的形式存在，不过只通过三种方式访问其中的元素：push，pop，deq，其中push和pop只会由持有该队列的线程访问，而deq操作则是否由其它worker线程来访问。对应到代码上则是：</p>

<blockquote><ul>
<li>ForkJoinTask&lt;?>[] queue：代表任务队列，环形数组；</li>
<li>int queueTop：队列头，push或者pop操作时，修改此值，因为只会被当前worker线程访问，所以是普通变量；</li>
<li>volatile int queueBase：队列尾部，deq操作时修改此值，会有多个线程访问，使用volatile。</li>
</ul>
</blockquote>

<h4>数据元素访问</h4>

<pre class="prettyprint linenums lang-java">
long u = (((s = queueTop) & (m = q.length - 1)) << ASHIFT) + ABASE;
UNSAFE.putOrderedObject(q, u, t);
queueTop = s + 1;         // or use putOrderedInt
</pre>


<p>上面的代码是从入队操作中的一段，前文提到queueTop保存队列头，那为什么不直接用queue[queueTop]=t来赋值就行了？了解原因之前，先来看看这两行代码在做什么：</p>

<pre class="prettyprint linenums lang-java">
(s = queueTop) & (m = q.length - 1) // queueTop % (q.length - 1)，也就是queueTop根据队列长度取模，
                                     // 取模后，就是队列头实际在数组中的索引；
</pre>


<p>那 Index &lt;&lt; ASHIFT + ABASE在算什么？先看看ASHIFT及ABASE的定义：</p>

<pre class="prettyprint linenums:983 lang-java">
    static {
        int s;
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class a = ForkJoinTask[].class;
            ABASE = UNSAFE.arrayBaseOffset(a);
            s = UNSAFE.arrayIndexScale(a);
        } catch (Exception e) {
            throw new Error(e);
        }
        if ((s & (s-1)) != 0)
            throw new Error("data type scale not a power of two");
        ASHIFT = 31 - Integer.numberOfLeadingZeros(s);
    }
</pre>


<p>再来看看UNSAFE.arrayBaseOffset及UNSAFE.arrayIndexScale的文档：</p>

<blockquote><p>public native int arrayBaseOffset(Class arrayClass)</p>

<p>Report the offset of the first element in the storage allocation of a
given array class.  If #arrayIndexScale  returns a non-zero value
for the same class, you may use that scale factor, together with this
base offset, to form new offsets to access elements of arrays of the
given class.</p>

<p>public native int arrayIndexScale(Class arrayClass)</p>

<p>Report the scale factor for addressing elements in the storage
allocation of a given array class.  However, arrays of &ldquo;narrow&rdquo; types
will generally not work properly with accessors like #getByte(Object, int) , so the scale > > factor for such classes is reported as zero.</p></blockquote>

<p>Java数组在实际存储时有一个对象头，后面才是实际的数组数据，而UNSAFE.arrayBaseOffset就是用来获取实际数组数据的偏移量；UNSAFE.arrayIndexScale则是获取对应数组元素占的字节数。这里的代码ABASE=16（数组对象头大小），s=4（ForkJoinTask对象引用占用字节数），ASIFT=2。</p>

<p>所以上面的Index &lt;&lt; ASHIFT + ABASE合起来就是Index左移2位=Index*4，也就是算Index的在数组中的偏移量，再加上ABASE就是Index在对象中的偏移量。也就是那一行代码主要就是算出来queueTop在队列数组中的实际偏移量，知道了这些，我们再来看第二行代码：</p>

<pre class="prettyprint linenums lang-java">
UNSAFE.putOrderedObject(q, u, t);
</pre>


<p>UNSAFE.putOrderedObject的文档：</p>

<blockquote><p>public native  void putOrderedObject(Object o,long offset, Object x)</p>

<p>Version of #putObjectVolatile(Object, long, Object)
that does not guarantee immediate visibility of the store to
other threads. This method is generally only useful if the
underlying field is a Java volatile (or if an array cell, one
hat is otherwise only accessed using volatile accesses).</p></blockquote>

<p>看的不明不白，找了下资料，<a href="http://robsjava.blogspot.com/2013/06/a-faster-volatile.html">这篇文章</a>及<a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6275329">这里</a>解释的比较清楚：</p>

<blockquote><p>Unsafe.putOrderedObject guarante that writes will not be re-orderd by instruction
reordering. Under the covers it uses the faster store-store barrier, rather than the the
slower store-load barrier, which is used when doing a volatile write.</p>

<p>write may be reordered with subsequent operations (or equivalently, might not be visible to
other threads) until some other volatile write or synchronizing action occurs)</p></blockquote>

<p>也就是说能够保证写写不会被重排序，但是不保证写会对其它线程可见，而volatile既保证写写不会被重排序，也保证写后对其它线程立即可见。可见Unsafe.putOrderedObject会比直接的volatile变量赋值速度会一点，<a href="http://robsjava.blogspot.com/2013/06/a-faster-volatile.html">这篇文章</a>则指出Unsafe.putOrderedObject会比volatile写快3倍。</p>

<p>了解清楚这两行代码的作用后，再来回答一开始提出的问题，为什么要这么用？结合代码中的文档及自己的理解，我觉得原因无非两点：</p>

<blockquote><ul>
<li>需要保证写入元素的顺序对其它worker线程一致，也就是不会产生写写重排序；</li>
<li>不需要保证写读是否重排序，因为如果其它worker线程需要从当前队列steal任务，那么首先必须得个性volatile字段
queueBase，而volatile的语义保证读之前的所有写操作的可见性，而Unsafe.putOrderedObject性能明显要好于
volatile写。</li>
</ul>
</blockquote>

<p><strong>不知道上面的理解是否正确，如有问题，请指正</strong>。</p>

<p>好吧，两行代码包含这么多的知识点。</p>

<h4>容量</h4>

<p>初始容量 1&lt;&lt;13，最大容量 1&lt;&lt;24，队列满时，以2倍的方式增长，所以容量一直是2的幂次方。下面是扩容时的代码：</p>

<pre class="prettyprint linenums:477 lang-java">
    /**
     * Creates or doubles queue array.  Transfers elements by
     * emulating steals (deqs) from old array and placing, oldest
     * first, into new array.
     */
    private void growQueue() {
        ForkJoinTask<?>[] oldQ = queue;
        int size = oldQ != null ? oldQ.length << 1 : INITIAL_QUEUE_CAPACITY;
        if (size > MAXIMUM_QUEUE_CAPACITY)
            throw new RejectedExecutionException("Queue capacity exceeded");
        if (size < INITIAL_QUEUE_CAPACITY)
            size = INITIAL_QUEUE_CAPACITY;
        ForkJoinTask<?>[] q = queue = new ForkJoinTask<?>[size];
        int mask = size - 1;
        int top = queueTop;
        int oldMask;
        if (oldQ != null && (oldMask = oldQ.length - 1) >= 0) {
            for (int b = queueBase; b != top; ++b) {
                long u = ((b & oldMask) << ASHIFT) + ABASE;
                Object x = UNSAFE.getObjectVolatile(oldQ, u);
                if (x != null && UNSAFE.compareAndSwapObject(oldQ, u, x, null))
                    UNSAFE.putObjectVolatile
                        (q, ((b & mask) << ASHIFT) + ABASE, x);
            }
        }
    }
</pre>


<p>有了开始的分析，这段代码就比较容易理解了：</p>

<blockquote><ol>
<li>从queueBase开始直到queueTop，通过UNSAFE.getObjectVolatile读取对应位置的元素；</li>
<li>通过UNSAFE.compareAndSwapObject将对应位置的元素设置为null；</li>
<li>如果上述CAS成功，则通过UNSAFE.putObjectVolatile将该元素写入到新的队列；</li>
</ol>
</blockquote>

<h4>入队</h4>

<pre class="prettyprint linenums:459 lang-java">
    final void pushTask(ForkJoinTask<?> t) {
        ForkJoinTask<?>[] q; int s, m;
        if ((q = queue) != null) {    // ignore if queue removed
            long u = (((s = queueTop) & (m = q.length - 1)) << ASHIFT) + ABASE;
            UNSAFE.putOrderedObject(q, u, t);
            queueTop = s + 1;         // or use putOrderedInt
            if ((s -= queueBase) <= 2)
                pool.signalWork();
            else if (s == m) 
                growQueue();
        }
    }
</pre>


<p>如果队列中的任务数大于2，则通知线程池唤醒或者创建一个worker线程；如果队列已经满了（s == m），则通过growQueue对队列进行扩容。</p>

<h4>出队</h4>

<p>出队分两种，一种从队列头部出队（当前worker线程），别一种从队列尾部出队（其它worker线程）。</p>

<p><strong>从队列头部出队：</strong></p>

<pre class="prettyprint linenums:546 lang-java">
    private ForkJoinTask<?> popTask() {
        int m;
        ForkJoinTask<?>[] q = queue;
        if (q != null && (m = q.length - 1) >= 0) {
            for (int s; (s = queueTop) != queueBase;) {
                int i = m & --s;
                long u = (i << ASHIFT) + ABASE; // raw offset
                ForkJoinTask<?> t = q[i];
                if (t == null)   // lost to stealer
                    break;
                if (UNSAFE.compareAndSwapObject(q, u, t, null)) {
                    queueTop = s; // or putOrderedInt
                    return t;
                }
            }
        }
        return null;
    }
</pre>


<p>主要逻辑如下：</p>

<blockquote><ol>
<li>在队列不为空的情况下，从queueTop &ndash; 1位置处读取元素；</li>
<li>如果元素不为null，则通过UNSAFE.compareAndSwapObject将queueBase对应的元素置为null；</li>
<li>如果上述CAS成功，将该元素返回，并将queueTop减1；如果CAS失败，则重试。</li>
</ol>
</blockquote>

<p><strong>从队列尾部出队：</strong></p>

<pre class="prettyprint linenums:506 lang-java">
    final ForkJoinTask<?> deqTask() {
        ForkJoinTask<?> t; ForkJoinTask<?>[] q; int b, i;
        if (queueTop != (b = queueBase) &&
            (q = queue) != null && // must read q after b
            (i = (q.length - 1) & b) >= 0 &&
            (t = q[i]) != null && queueBase == b &&
            UNSAFE.compareAndSwapObject(q, (i << ASHIFT) + ABASE, t, null)) {
            queueBase = b + 1;
            return t;
        }
        return null;
    }
</pre>


<p>主要逻辑如下：</p>

<blockquote><ol>
<li>在队列不为空，并且queueBase对应位置的元素不为null，从queueBase读取元素；</li>
<li>通过UNSAFE.compareAndSwapObject将queueBase对应的元素置为null；</li>
<li>如果上述CAS成功，将queueBase位置对应的元素返回，并将queueBase加1。</li>
</ol>
</blockquote>

<h3>提交任务</h3>

<p>ForkJoinPool提供了类似ThreadPoolExecutor的接口来提供普通任务或者ForkJoinTask，这些接口最终都会调用forkOrSubmit来完成任务提交：</p>

<pre class="prettyprint linenums:1529 lang-java">
    private <T> void forkOrSubmit(ForkJoinTask<T> task) {
        ForkJoinWorkerThread w;
        Thread t = Thread.currentThread();
        if (shutdown)
            throw new RejectedExecutionException();
        if ((t instanceof ForkJoinWorkerThread) &&
            (w = (ForkJoinWorkerThread)t).pool == this)
            w.pushTask(task);
        else
            addSubmission(task);
    }
</pre>


<p>可以看到，forkOrSubmit要么将任务提交到对应worker线程的任务队列（提交任务的线程本身就是worker线程，并且该worker线程属于当前ForkJoinPool，通过w.pushTask提交任务，前文已分析过），要么将任务提交到ForkJoinPool提供的任务队列。</p>

<p>看一下addSubmission的实现：</p>

<pre class="prettyprint linenums:1529 lang-java">
    private void addSubmission(ForkJoinTask<?> t) {
        final ReentrantLock lock = this.submissionLock;
        lock.lock();
        try {
            ForkJoinTask<?>[] q; int s, m;
            if ((q = submissionQueue) != null) {    // ignore if queue removed
                long u = (((s = queueTop) & (m = q.length-1)) << ASHIFT)+ABASE;
                UNSAFE.putOrderedObject(q, u, t);
                queueTop = s + 1;
                if (s - queueBase == m)
                    growSubmissionQueue();
            }
        } finally {
            lock.unlock();
        }
        signalWork();
    }
</pre>


<p>基本逻辑跟pushTask一致，只不过多加了个锁（同一时间，可能会有多个外部线程提交任务），并且是每加一个任务就会调用singalWork。</p>

<h3>fork子任务</h3>

<p>也就是当前任务fork一个子任务，看一下实现：</p>

<pre class="prettyprint linenums:621 lang-java">
    public final ForkJoinTask<V> fork() {
        ((ForkJoinWorkerThread) Thread.currentThread())
            .pushTask(this);
        return this;
    }
</pre>


<p>比较简单，就是将任务提交到当前worker线程的任务队列。</p>

<h3>join子任务</h3>

<p>等待子任务的完成：</p>

<pre class="prettyprint linenums:638 lang-java">
    public final V join() {
        if (doJoin() != NORMAL)
            return reportResult();
        else
            return getRawResult();
    }
</pre>




<pre class="prettyprint linenums:348 lang-java">
    private int doJoin() {
        Thread t; ForkJoinWorkerThread w; int s; boolean completed;
        if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) {
            if ((s = status) < 0)
                return s;
            if ((w = (ForkJoinWorkerThread)t).unpushTask(this)) {
                /**
                 * unpushTask与上面分析的popTask实现类似，只是多了个判断，队列头的任务是不是当前任务。
                 * 也就是说，当join任务时，如果当前任务就在队列头部，就直接在当前worker线程执行。
                 */
                try {
                    completed = exec();
                } catch (Throwable rex) {
                    return setExceptionalCompletion(rex);
                }
                if (completed)
                    return setCompletion(NORMAL);
            }
            
            /**
             * 任务不在队列头部，调用joinTask等待任务完成。
             */
            return w.joinTask(this);
        }
        else
            /**
             * 不是worker线程，直接调用Object.wait等待任务完成。
             */
            return externalAwaitDone();
    }
</pre>


<p>我们来看一下joinTask的实现：</p>

<pre class="prettyprint linenums:708 lang-java">
    final int joinTask(ForkJoinTask<?> joinMe) {
        ForkJoinTask<?> prevJoin = currentJoin;
        currentJoin = joinMe;
        for (int s, retries = MAX_HELP;;) {
            if ((s = joinMe.status) < 0) {
                currentJoin = prevJoin;
                return s;
            }
            if (retries > 0) {
                if (queueTop != queueBase) {
                    if (!localHelpJoinTask(joinMe))
                        retries = 0;           // cannot help
                }
                else if (retries == MAX_HELP >>> 1) {
                    --retries;                 // check uncommon case
                    if (tryDeqAndExec(joinMe) >= 0)
                        Thread.yield();        // for politeness
                }
                else
                    retries = helpJoinTask(joinMe) ? MAX_HELP : retries - 1;
            }
            else {
                retries = MAX_HELP;           // restart if not done
                pool.tryAwaitJoin(joinMe);
            }
        }
    }
</pre>


<p>主要流程：</p>

<blockquote><ol>
<li>localHelpJoinTask：如果当前工作线程的任务队列不为空，则尝试在当前线程执行一个任务（未必是要join的任务）；但是如果任务队列的头部已经有一个任务在等待任务完成，则通过Object.wait等待任务完成；</li>
<li>tryDeqAndExec：如果要join的任务在某个工作线程任务队列的尾部，则直接把任务偷取过来并执行；</li>
<li>helpJoinTask：找到偷取当前任务的工作线程，并从其队列尾部偷取一个任务执行；如果该工作线程也在等待一个任务完成，则继续递归寻找偷取该任务的工作线程。</li>
</ol>
</blockquote>

<h3>偷取任务</h3>

<p>偷取任务的逻辑很简单，就是从其它工作线程的队列尾部（queueBase）出队一个任务，并在当前工作线程中执行。可以看一下helpJoinTask中的一段代码：</p>

<pre class="prettyprint linenums:806 lang-java">
    if (t != null && v.queueBase == b &&
        UNSAFE.compareAndSwapObject(q, u, t, null)) { // 获取到队列尾部的任务，通过CAS将队列中对应位置设为null
        v.queueBase = b + 1; // 更新queueBase
        v.stealHint = poolIndex; // 将stealHint设为当前工作线程
        ForkJoinTask<?> ps = currentSteal;
        currentSteal = t;
        t.doExec(); // 在当前工作线程中执行偷取到的任务
        currentSteal = ps;
        helped = true;
    }
</pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java并发源码分析 - ThreadPoolExecutor]]></title>
    <link href="http://onlychoice.github.io/blog/2013/09/13/java-concurrent-source-code-reading-2/"/>
    <updated>2013-09-13T14:32:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/09/13/java-concurrent-source-code-reading-2</id>
    <content type="html"><![CDATA[<h2>为什么需要线程池？</h2>

<blockquote><ol>
<li>避免在运行大量任务时，频繁的线程创建和销毁开销；</li>
<li>使资源的使用得到有效控制，避免创建过多的线程占用系统资源。</li>
</ol>
</blockquote>

<!--more-->


<h2>基本概念</h2>

<h3>Core and maximum pool sizes</h3>

<p>控制线程池核心线程数以及最大可生成的线程数量。是否需要创建线程与当前线程的数量以及任务队列的状态在关，后面会详述。</p>

<h3 id="timeout">Keep-alive times</h3>


<p>默认情况下，只有在当前worker线程数大于core大小的情况下，空闲一定时间的worker线程才可以被回收，但是也可以通过allowCoreThreadTimeOut(boolean)函数来控制core线程的超时时间。</p>

<h3>任务队列</h3>

<p>ThreadPoolExecutor使用BlockingQueue来管理任务队列，任务队列与线程池大小的关系如下：</p>

<blockquote><ul>
<li>如果线程池数量小于corePoolSize，Executor倾向于新增worker线程；</li>
<li>如果线程池数量多于或者等于corePoolSize倾向于将任务放入队列；</li>
<li>如果任务队列已满，并且线程池数量还没有超过maximumPoolSize，那么新的worker线程；</li>
<li>如果任务队列已满，并且线程池数量已经超过maximumPoolSize，那么任务被reject；</li>
</ul>
</blockquote>

<h2>实现</h2>

<h3>提交任务</h3>

<pre class="prettyprint linenums:1300 lang-java">
    public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();

        int c = ctl.get();
        if (workerCountOf(c) < corePoolSize) {
            /**
             * 如果当前worker数量小于corePoolSize，则创建新的worker。
             */
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        
        /**
         * 尝试将任务添加到任务队列。
         */
        if (isRunning(c) && workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) && remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        /**
         * 在worker数量大于corePoolSize，并且任务添加到队列失败（队列满）的情况下，尝试创建新的worker，
         * 如果创建失败表示已经达到maximumPoolSize，则reject任务。
         */
        else if (!addWorker(command, false))
            reject(command);
    }
</pre>


<h3>创建worker线程</h3>

<p>去除一些状态检查后，核心代码如下：</p>

<pre class="prettyprint linenums:886 lang-java">
    private boolean addWorker(Runnable firstTask, boolean core) {
        Worker w = new Worker(firstTask);
        Thread t = w.thread;

        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            workers.add(w);

            int s = workers.size();
            if (s > largestPoolSize)
                largestPoolSize = s;
        } finally {
            mainLock.unlock();
        }

        t.start();

        return true;
    }
</pre>


<p>可以看到，很简单，创建一个Worker线程，将他加到workers集合中，然后启动对应worker线程，DONE。</p>

<p>我们来看看Worker的定义：</p>

<pre class="prettyprint linenums:575 lang-java">
    private final class Worker
        extends AbstractQueuedSynchronizer
        implements Runnable
    {
        /**
         * This class will never be serialized, but we provide a
         * serialVersionUID to suppress a javac warning.
         */
        private static final long serialVersionUID = 6138294804551838833L;

        /** Thread this worker is running in.  Null if factory fails. */
        final Thread thread;
        /** Initial task to run.  Possibly null. */
        Runnable firstTask;
        /** Per-thread task counter */
        volatile long completedTasks;

        /**
         * Creates with given first task and thread from ThreadFactory.
         * @param firstTask the first task (null if none)
         */
        Worker(Runnable firstTask) {
            this.firstTask = firstTask;
            this.thread = getThreadFactory().newThread(this);
        }

        /** Delegates main run loop to outer runWorker  */
        public void run() {
            runWorker(this);
        }

        // Lock methods
        //
        // The value 0 represents the unlocked state.
        // The value 1 represents the locked state.

        protected boolean isHeldExclusively() {
            return getState() == 1;
        }

        protected boolean tryAcquire(int unused) {
            if (compareAndSetState(0, 1)) {
                setExclusiveOwnerThread(Thread.currentThread());
                return true;
            }
            return false;
        }

        protected boolean tryRelease(int unused) {
            setExclusiveOwnerThread(null);
            setState(0);
            return true;
        }

        public void lock()        { acquire(1); }
        public boolean tryLock()  { return tryAcquire(1); }
        public void unlock()      { release(1); }
        public boolean isLocked() { return isHeldExclusively(); }
    }
</pre>


<p>除去跟锁定义相关的代码后，核心就是run函数的实现：调用runWorker运行Worker线程的运行逻辑。</p>

<h3>Worker线程运行逻辑</h3>

<pre class="prettyprint linenums:1098 lang-java">
    final void runWorker(Worker w) {
        Runnable task = w.firstTask;
        w.firstTask = null;
        boolean completedAbruptly = true;
        try {
            while (task != null || (task = getTask()) != null) {
                w.lock();
                clearInterruptsForTaskRun();
                try {
                    beforeExecute(w.thread, task);
                    Throwable thrown = null;
                    try {
                        task.run();
                    } catch (RuntimeException x) {
                        thrown = x; throw x;
                    } catch (Error x) {
                        thrown = x; throw x;
                    } catch (Throwable x) {
                        thrown = x; throw new Error(x);
                    } finally {
                        afterExecute(task, thrown);
                    }
                } finally {
                    task = null;
                    w.completedTasks++;
                    w.unlock();
                }
            }
            completedAbruptly = false;
        } finally {
            processWorkerExit(w, completedAbruptly);
        }
    }
</pre>


<p>就是一个while循环，在有任务的情况下（两种：一种在创建Worker线程时传入，由firtstTask传入；一种通过getTask由任务队列获取），执行任务，并调用设置的回调函数（beforeExecute，afterExecute等）。</p>

<p>我们来看看getTask的实现：</p>

<pre class="prettyprint linenums:1098 lang-java">
    private Runnable getTask() {
        boolean timedOut = false; // Did the last poll() time out?
        for (;;) {
            try {
                Runnable r = timed ?
                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                    workQueue.take();
                if (r != null)
                    return r;
                timedOut = true;
            } catch (InterruptedException retry) {
                timedOut = false;
            }
        }
    }
</pre>


<p>去除了状态检查的相关代码后，核心的逻辑如下：在需要处理<a href="#timeout">超时</a>的情况下调用BlockingQueue.poll来获取任务，如果在超时后还没有任务，则让相应的worker线程退出；如果不需要处理超时时候，调用BlockingQueue.take，阻塞当前worker线程一直到有任务到达。</p>

<h3>总结</h3>

<p>ThreadPoolExecutor会根据线程池状态和任务队列状态创建worker线程，而每个worker线程的主要任务就是不断的去任务队列里去拿任务：要么一直阻塞等，要么超时后退出；拿到任务后，运行任务并调用相关回调。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java并发源码分析 - 锁]]></title>
    <link href="http://onlychoice.github.io/blog/2013/08/31/java-concurrent-source-code-reading-1/"/>
    <updated>2013-08-31T16:07:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/08/31/java-concurrent-source-code-reading-1</id>
    <content type="html"><![CDATA[<p>（注：文章里涉及到的代码分析，基于jdk1.7.0_10 Hotspot 64-Bit）</p>

<h2>基本概念</h2>

<p>Java同步机制除了内置的synchronized（包含Object.wait/notify）以外，还通过concurrent包提供了多种锁，包含ReentrantLock、Semaphore、ReentrantReadWriteLock等，以及跟Object.wait/notify类似语义的Condition接口。</p>

<!--more-->


<h4>接口定义</h4>

<p>具体的接口（Lock，Condition）就不在这里赘述，只做个简单总结：</p>

<blockquote><ol>
<li>Lock接口提供三种不同类型的获取锁接口：不响应中断（interrupt）、响应中断、可以设置超时；</li>
<li>Condition接口提供类似Object.wait语义的四种await接口：不响应中断（interrupt）、响应中断、可以设置超时、可以设置deadline；不管哪一种await，都必须在调用前持有跟该Condition对象关联的锁，Condition的实现会保证await调用在进入阻塞状态前释放锁，并且在await调用返回时，重新持有锁。</li>
</ol>
</blockquote>

<h4>锁类型</h4>

<blockquote><ol>
<li>同synchronized一样，concurrent包里提供的锁都是可重入的（reentrant）：一个线程在持有一个锁时，在不释放该锁的前提下，可多次重新持有该锁；</li>
<li>互斥锁和共享锁：在一个线程持有锁的时候，如果其它线程不能再持有该锁，则为互斥锁，否则为共享锁；concurrent包里的ReentrantLock为互斥锁，Semaphore为共享锁，ReentrantReadWriteLock是共享锁及互斥锁的结合；</li>
<li>公平锁和非公平锁：公平锁保证线程以FIFO的顺序持有锁（不包含tryLock接口），但非公平锁不保证这点：在有线程在排队等待获取当前锁的时候，新的线程可以直接竞争成功并持有锁；</li>
</ol>
</blockquote>

<h2>基本框架</h2>

<p>简单查看一下ReetrantLock、Semaphore等类的实现，会发现都依赖于AbstractQueuedSynchronizer（AQS）这个类，这个其实是concurrent包里实现同步机制的一个核心框架，可以通过这篇<a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf" title="The java.util.concurrent Synchronizer Framework">论文</a>来了解这个框架。该框架的核心实现要素包含以下三点：</p>

<blockquote><ol>
<li>同步状态的原子性管理</li>
<li>等待队列的管理</li>
<li>线程的阻塞和唤醒</li>
</ol>
</blockquote>

<h4>同步状态的原子性管理</h4>

<p>AQS将状态定义为一个整型变量（volatile int state），对它的修改AQS提供了两个接口，一个是基于volatile语义：</p>

<pre class="prettyprint linenums:549 lang-java">
    protected final void setState(int newState) {
        state = newState;
    }
</pre>


<p>另外一个依赖于Unsafe.compareAndSwapInt：</p>

<pre class="prettyprint linenums:564 lang-java">
    protected final boolean compareAndSetState(int expect, int update) {
        // See below for intrinsics setup to support this
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
    }
</pre>


<p>那什么时候用setState，什么时候用compareAndSetState呢？简单看了下调用关系，有如下特征：</p>

<blockquote><ul>
<li>初始化state时一般用setState，比如：Semaphore、CountDownLatch、ReentrantReadWriteLock等的AQS子类初始化；</li>
<li>互斥锁的可重入处理逻辑中一般调用setState，比如：ReentrantLock的tryAcquire，ReentrantReadWriteLock的tryAcquire；</li>
<li>互斥锁的释放锁操作一般调用setState，比如：ReentrantLock的tryRelease，ReentrantReadWriteLock的tryRelease；</li>
<li>其它情况下都调用compareAndSetState。</li>
</ul>
</blockquote>

<p>从以上的情况来看，应该是在基本无竞争（初始化，重入处理、互斥锁的释放）的情况下调用setState；竞争比较激烈的情况下调用compareAndSetState。</p>

<h4>等待队列的管理</h4>

<p>AQS使用CLH队列的变种来管理等待线程，每个等待线程为一个结点（AbstractQueuedSynchronizer.Node），后文会混用结点和线程。</p>

<p>CLH队列中结点之间并不存在实际的连接，后继结点在等待锁的时候只是在前续结点的状态字段上自旋，直到获取锁。<a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf" title="The java.util.concurrent Synchronizer Framework">论文</a>对AQS使用prev及next字段的解释是：</p>

<blockquote><ol>
<li>prev主要为了完成超时及取消语义：如果前继结点取消，那么就是向前找到一个未取消的前继结点；</li>
<li>next的主要作用在于优化后继结点的查找，避免每次都需要从tail结点向前反向查找。</li>
</ol>
</blockquote>

<h4>线程的阻塞和唤醒</h4>

<p>依赖于LockSupport.park（阻塞当前线程，实际调用Unsafe.park）及LockSupport.unpark（唤醒指定线程，实际调用Unsafe.unpark）；根据LockSupport的Java doc可以了解到以下内容：</p>

<blockquote><ul>
<li>park与unpark使用类似Semaphore的许可机制，如果当前线程拥有许可，那个park会消费掉该许可，并立即返回；如果当前线程没有许可，则当前线程会阻塞；unpark会导致指定线程的许可可用；</li>
<li>许可不会累加，最多只有一个，也就是说连续多次的unpark并不会导致许可变多，也就是说如下<a href="http://whitesock.iteye.com/blog/1336409" title="Inside AbstractQueuedSynchronizer (1)">代码</a>还是会导致当前线程阻塞：</li>
</ul>
</blockquote>

<pre class="prettyprint linenums lang-java">
LockSupport.unpark(Thread.currentThread());  
LockSupport.unpark(Thread.currentThread());  
LockSupport.park();  
LockSupport.park();  
</pre>


<blockquote><ul>
<li>关于park()和park(Object blocker)的区别，Object blocker参数的作用在于允许记录当前线程被阻塞的原因，以便监控分析工具进行分析。官方的文档中也更建议使用park(Object blocker)。</li>
</ul>
</blockquote>

<h3>AQS实现</h3>

<p>分析AQS之前先了解下concurrent包里的类是如何使用AQS的。AQS是抽象类，ReentrantLock、Semaphore等类会在使用时定义一个子类（Sync，一般还会根据是否是公平锁定义FireSync、NonfairSync），根据具体的需要重写AQS定义的四个protected接口：</p>

<pre class="prettyprint linenums lang-java">
/**
 * 用于互斥锁。
 */
protected boolean tryAcquire(int arg);
protected boolean tryRelease(int arg);

/**
 * 用于共享锁。
 */
protected int tryAcquireShared(int arg);
protected boolean tryReleaseShared(int arg);
</pre>


<p>注意返回值上，只有tryAcquireShared的返回值为int：大于0时，代表当前获取锁成功，后续的获取锁请求也可能会成功；等于0时，代表当前获取锁成功，后续获取锁请求必须等待；小于0时，代表当前获取锁失败，必须等待；其它返回值都为boolean，true则成功，false失败。</p>

<p>上述这几个接口的主要作用是什么呢？将管理锁（或者其它实现）的状态的任务交给具体实现类，这样AQS就不需要知道各个不同锁机制的状态之间的差别，从而简化AQS的实现。</p>

<p>然后具体的锁实现会调用AQS定义的几个公有方法来获取或者释放锁：</p>

<pre class="prettyprint linenums lang-java">
/**
 * 用于互斥锁：分别对应不响应中断、响应中断、可设置超时的获取锁接口.
 */
public final void acquire(int arg);
public final void acquireInterruptibly(int arg) throws InterruptedException;
public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException;
public final boolean release(int arg);

/**
 * 用于共享锁：分别对应不响应中断、响应中断、可设置超时的获取锁接口.
 */
public final void acquireShared(int arg);
public final void acquireSharedInterruptibly(int arg) throws InterruptedException;
public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException;
public final boolean releaseShared(int arg);
</pre>


<h4>addWaiter：等待队列的加入</h4>

<pre class="prettyprint linenums:605 lang-java">
    private Node addWaiter(Node mode) {
        Node node = new Node(Thread.currentThread(), mode);
        // Try the fast path of enq; backup to full enq on failure
        Node pred = tail;
        if (pred != null) {
            /**
             * 通过CAS来更改队列tail结点。             
             * 注意：在并发访问时，这里的CAS成功，可以保证prev结点非null，但next结点有可能为null。
             */
            node.prev = pred;
            if (compareAndSetTail(pred, node)) {
                pred.next = node;
                return node;
            }
        }
        enq(node);
        return node;
    }
</pre>




<pre class="prettyprint linenums:605 lang-java">
    private Node enq(final Node node) {
        for (;;) {
            Node t = tail;
            if (t == null) { // Must initialize
                 /**
                  * 这里多了个初始化：也就是有需要时才初始化head结点。
                  */
                if (compareAndSetHead(new Node()))
                    tail = head;
            } else {
                /**
                 * 通过CAS来更改队列tail结点。
                 * 注意：在并发访问时，这里的CAS成功，可以保证prev结点非null，但next结点有可能为null。
                 */
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                    t.next = node;
                    return t;
                }
            }
        }
    }
</pre>


<p>从上面的代码可以知道，结点的加入只是简单的通过CAS更新队列的tail字段：保证prev跟tail的原子更新，但不保证tail与next的原子更新。</p>

<h4>acquire：互斥锁获取</h4>

<pre class="prettyprint linenums:1196 lang-java">
    public final void acquire(int arg) {
        /*
         * 调用具体实现类的tryAcquire，如果返回true，则认为获取锁成功，当前函数返回；
         * 如果返回false，则将当前线程加入锁的等待队列（addWaiter，并且注意这里的加的
         * 等待结点类型为Node.EXCLUSIVE，也就是互斥锁），当前线程会进入休眠（dormant）
         * 状态，并等待前继结点唤醒，然后重新竞争锁，直到获取锁后返回。
         *
         * acquireQueued返回true说明线程在等待过程中被中断过（interrupted），则通过
         * selfInterrupt（实际调用Thread.currentThread().interrupt()）重新
         * interrupte当前线程以向调用者传递中断信号。
         */
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
</pre>




<pre class="prettyprint linenums:855 lang-java">
    final boolean acquireQueued(final Node node, int arg) {
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head && tryAcquire(arg)) {
                     /**
                      * 只有在当前结点的前继结点为head时，当前结点去才会尝试获取锁。
                      * 获取锁成功时（tryAcquire返回true），将当前结点设置成head，
                      * 并根据中断状态返回true或者false。
                      */
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return interrupted;
                }
                
                /**
                 * shouldParkAfterFailedAcquire判断是否应该阻塞（park）当前线程，判断的依据是
                 * 前继结点的状态（p.waitStatus），只有该状态为Node.SIGNAL时才会阻塞当前线程：
                 * 此状态说明，当前结点无法暂时获取锁，并且前继结点保证会在释放锁的时候唤醒当前线程。
                 *
                 * parkAndCheckInterrupt的实现就比较简单了，调用LockSupport.park(this)阻塞
                 * 当前线程，并返回线程当前的中断状态。
                 */
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</pre>


<h4>release：互斥锁的释放</h4>

<pre class="prettyprint linenums:1259 lang-java">
    public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null && h.waitStatus != 0)
                /**
                 * 在head不为null，并且waitStatus不为0的情况下，唤醒后继结点：只是给后续结点一次
                 * 竞争锁的机会，后续结点未必能获取到锁。 
                 *
                 * unparkSuccessor的实现：找到h的后继结点，并调用LockSupport.unpark唤醒后继结点
                 * 对应的线程。
                 */
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
</pre>


<h4>acquireShared：共享锁获取</h4>

<pre class="prettyprint linenums:946 lang-java">
    public final void acquireShared(int arg) {
        /**
         * 调用具体实现类的tryAcquireShared，如果返回值不小于0，则认为获取共享锁成功；
         * 否则通过doAcquireShared调用进入等待锁逻辑。
         */
        if (tryAcquireShared(arg) < 0)
            doAcquireShared(arg);
    }
</pre>




<pre class="prettyprint linenums:946 lang-java">
    private void doAcquireShared(int arg) {
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r >= 0) {
                        /**
                         * 仔细与上面的互斥锁的获取逻辑比较下，会发现逻辑基本差不多：
                         * 前继结点为head，并且获取锁成功（与互斥锁不同的时tryAcquireShared返回值
                         * 不小于0时，认为获取锁成功）；不但要将当前结点设置为head结点，并且要将此事件
                         * 向后传递（setHeadAndPropagate）。
                         */
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        if (interrupted)
                            selfInterrupt();
                        failed = false;
                        return;
                    }
                }
                
                /**
                 * 与互斥锁逻辑一致
                 */
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</pre>




<pre class="prettyprint linenums:708 lang-java">
    private void setHeadAndPropagate(Node node, int propagate) {
        Node h = head; // Record old head for check below
        setHead(node);
        /*
         * Try to signal next queued node if:
         *   Propagation was indicated by caller,
         *     or was recorded (as h.waitStatus) by a previous operation
         *     (note: this uses sign-check of waitStatus because
         *      PROPAGATE status may transition to SIGNAL.)
         * and
         *   The next node is waiting in shared mode,
         *     or we don't know, because it appears null
         *
         * The conservatism in both of these checks may cause
         * unnecessary wake-ups, but only when there are multiple
         * racing acquires/releases, so most need signals now or soon
         * anyway.
         */
        if (propagate > 0 || h == null || h.waitStatus < 0) {
            Node s = node.next;
            if (s == null || s.isShared())
                doReleaseShared();
        }
    }
</pre>


<p>setHeadAndPropagate除了将head设置为当前持有锁的结点外，还需要保证在后面这两种情况下向后传播可以获取锁的信息：</p>

<blockquote><ol>
<li>propagate > 0（也就是tryAcquireShared > 0，表示后续的获取锁操作也可能成功）；</li>
<li>原始head结点的waitStatus &lt; 0，也就是以前有某个结点希望释放锁的操作向后传播。</li>
</ol>
</blockquote>

<h4>releaseShared：共享锁的释放</h4>

<pre class="prettyprint linenums:1339 lang-java">
    public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {
            doReleaseShared();
            return true;
        }
        return false;
    }
</pre>




<pre class="prettyprint linenums:670 lang-java">
    private void doReleaseShared() {
        for (;;) {
            Node h = head;
            if (h != null && h != tail) {
                int ws = h.waitStatus;
                if (ws == Node.SIGNAL) {
                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                        continue;            // loop to recheck cases
                    unparkSuccessor(h);
                }
                else if (ws == 0 &&
                         !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                    continue;                // loop on failed CAS
            }
            if (h == head)                   // loop if head changed
                break;
        }
    }
</pre>


<p>可以看到，doReleaseShared需要保证两点：</p>

<blockquote><ol>
<li>要么至少唤醒一个等待的结点：waitStatus == Node.SIGNAL；</li>
<li>要么将当前head结点的waitStatus设置成Node.PROPAGATE，以保证在后续线程持有到锁后，可以向后传播此次释放锁事件（见setHeadAndPropagate的分析）。</li>
</ol>
</blockquote>

<h2>具体锁实现</h2>

<h3>ReentrantLock</h3>

<p>互斥模式，state代表互斥锁的状态：为0说明当前锁可用；为1说明当前锁已经被某个线程持有，其它线程必须等待。获取锁等价于将state设置成1；释放锁等价于将state设置为0。</p>

<h4>公平锁获取</h4>

<pre class="prettyprint linenums:236 lang-java">
        protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (!hasQueuedPredecessors() &&
                    compareAndSetState(0, acquires)) {
                    /**
                     * 只有在等待队列里没有前继等待线程时（!hasQueuedPredecessors），
                     * 当前线程才能尝试获取锁（更新锁状态：compareAndSetState(0, acquires)），
                     * 如果成功则将当前线程标记为锁持有者，并且返回true。
                     */
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                /**
                 * 处理重入逻辑：当前线程持有锁，并且又发起获取锁请求
                 */
                int nextc = c + acquires;
                if (nextc < 0)
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
</pre>


<h4>非公平锁获取</h4>

<pre class="prettyprint linenums:217 lang-java">
        protected final boolean tryAcquire(int acquires) {
            return nonfairTryAcquire(acquires);
        }
</pre>




<pre class="prettyprint linenums:133 lang-java">
        final boolean nonfairTryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                /**
                 * 跟公平锁获取相比，这里没有判断是否有前继等待线程。也就是说当前线程可以在等待队列里
                 * 有线程在等待获取锁的时候，竞争成功并且持有锁，这对其它等待线程来说，就是不公平的。
                 */
                if (compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0) // overflow
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
</pre>


<h3>ReentrantReadWriteLock</h3>

<p>共享互斥模式结合：写锁对应互斥锁，读锁对应共享锁。state被分为两部分：高16位代表读锁持有数量；低16位代表写锁持有数量。</p>

<p>主要的实现逻辑跟ReentrantLock类似，但因为同时有两个锁，所以有些不同：</p>

<blockquote><ol>
<li>在写锁被当前线程持有的情况下，其它线程不同持有任意锁；</li>
<li>在写锁被当前线程持有的情况下，当前线程可以继续请求获取读锁和写锁；</li>
<li>在读锁被当前线程持有的情况下，其它线程可以持有读锁，不能持有写锁；</li>
<li>在读锁被当前线程持有的情况下，当前线程和其它持有读锁的线程可以继续请求获取读锁，不能请求获取写锁。</li>
</ol>
</blockquote>

<p>代码就不详细说明了。</p>

<h3>Semaphore</h3>

<p>共享模式，state代表许可的个数，初始为许可的个数，每一次的acquire，许可减1。注意：tryAcquireShared返回为int，这里会返回剩余的许可个数。</p>

<p>公平与非公平的处理与ReentrantLock处理逻辑类似，不再详细分析。</p>

<h3>CountDownLatch</h3>

<p>共享模式，state代表count个数，初始为count个数。下面为核心代码：</p>

<pre class="prettyprint linenums:177 lang-java">
        protected int tryAcquireShared(int acquires) {
            return (getState() == 0) ? 1 : -1;
        }

        protected boolean tryReleaseShared(int releases) {
            // Decrement count; signal when transition to zero
            for (;;) {
                int c = getState();
                if (c == 0)
                    return false;
                int nextc = c-1;
                if (compareAndSetState(c, nextc))
                    return nextc == 0;
            }
        }
</pre>


<p>可以看到，在初始情况下，所有的tryAcquireShared（CountDownLatch.await会调用此方法）都会阻塞（getState == count，不为0）；每一次的tryReleaseShared（CountDownLatch.countDown会调用此方法）将count减1，直到为0并且会返回true（nextc == 0），这时acquireShared会调用doReleaseShared唤醒被阻塞的线程（getState == 0保证tryAcquireShared肯定会成功）。</p>

<h3>FutureTask</h3>

<p>共享模式，state代表任务的完成状态：0代表任务已经准备就绪，1代表任务正在运行，2代表任务已经完成，4代表任务取消。</p>

<pre class="prettyprint linenums:223 lang-java">
        /**
         * Implements AQS base acquire to succeed if ran or cancelled
         */
        protected int tryAcquireShared(int ignore) {
            return innerIsDone() ? 1 : -1;
        }

        /**
         * Implements AQS base release to always signal after setting
         * final done status by nulling runner thread.
         */
        protected boolean tryReleaseShared(int ignore) {
            runner = null;
            return true;
        }
</pre>


<p>由上面代码可以看到在任务没有完成时，任何调用tryAcquireShared（FutureTask.get会调用此方法）的线程都会阻塞；tryReleaseShared永远返回true。</p>

<p>任务执行完成后，会将state设置成2（正常完成或者出现异常）或者4（任务被取消）：innerIsDone方法在这两种情况下都会返回true。</p>
]]></content>
  </entry>
  
</feed>
