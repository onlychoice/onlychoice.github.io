<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rabbitmq | SHOW ME THE CODE]]></title>
  <link href="http://onlychoice.github.io/blog/categories/rabbitmq/atom.xml" rel="self"/>
  <link href="http://onlychoice.github.io/"/>
  <updated>2013-12-12T14:52:45+08:00</updated>
  <id>http://onlychoice.github.io/</id>
  <author>
    <name><![CDATA[Zhihui Jiao]]></name>
    <email><![CDATA[jzhihui521@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[RabbitMQ持久化机制]]></title>
    <link href="http://onlychoice.github.io/blog/2013/11/15/rabbitmq-persistent/"/>
    <updated>2013-11-15T14:29:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/11/15/rabbitmq-persistent</id>
    <content type="html"><![CDATA[<p>之前其实已经写过一篇关于RabbitMQ持久化的<a href="http://jzhihui.iteye.com/blog/1642324">文章</a>，但那篇文章侧重代码层面的写入流程，对于持久化操作何时发生以及什么时候会刷新到磁盘等问题其实都没有搞清楚，这篇文章着重于关注这些问题。</p>

<!--more-->


<h3>消息什么时候需要持久化？</h3>

<p>根据<a href="http://www.rabbitmq.com/blog/2011/01/20/rabbitmq-backing-stores-databases-and-disks/">官方博文</a>的介绍，RabbitMQ在两种情况下会将消息写入磁盘：</p>

<blockquote><ol>
<li>消息本身在publish的时候就要求消息写入磁盘；</li>
<li>内存紧张，需要将部分内存中的消息转移到磁盘；</li>
</ol>
</blockquote>

<h3>消息什么时候会刷到磁盘？</h3>

<blockquote><ol>
<li>写入文件前会有一个Buffer，大小为1M（1048576），数据在写入文件时，首先会写入到这个Buffer，如果Buffer已满，则会将Buffer写入到文件（未必刷到磁盘）；</li>
<li>有个固定的刷盘时间：25ms，也就是不管Buffer满不满，每隔25ms，Buffer里的数据及未刷新到磁盘的文件内容必定会刷到磁盘；</li>
<li>每次消息写入后，如果没有后续写入请求，则会直接将已写入的消息刷到磁盘：使用Erlang的receive x after 0来实现，只要进程的信箱里没有消息，则产生一个timeout消息，而timeout会触发刷盘操作。</li>
</ol>
</blockquote>

<h3>消息在磁盘文件中的格式</h3>

<p>消息保存于$MNESIA/msg_store_persistent/x.rdq文件中，其中x为数字编号，从1开始，每个文件最大为16M（16777216），超过这个大小会生成新的文件，文件编号加1。消息以以下格式存在于文件中：</p>

<blockquote><p>&lt;&lt;Size:64, MsgId:16/binary, MsgBody>></p></blockquote>

<p>MsgId为RabbitMQ通过rabbit_guid:gen()每一个消息生成的GUID，MsgBody会包含消息对应的exchange，routing_keys，消息的内容，消息对应的协议版本，消息内容格式（二进制还是其它）等等。</p>

<h4>文件何时删除？</h4>

<p>当所有文件中的垃圾消息（已经被删除的消息）比例大于阈值（GARBAGE_FRACTION = 0.5）时，会触发文件合并操作（至少有三个文件存在的情况下），以提高磁盘利用率。</p>

<p>publish消息时写入内容，ack消息时删除内容（更新该文件的有用数据大小），当一个文件的有用数据等于0时，删除该文件。</p>

<h3>消息索引什么时候需要持久化？</h3>

<p>索引的持久化与消息的持久化类似，也是在两种情况下需要写入到磁盘中：要么本身需要持久化，要么因为内存紧张，需要释放部分内存。</p>

<h3>消息索引什么时候会刷到磁盘？</h3>

<blockquote><ol>
<li>有个固定的刷盘时间：25ms，索引文件内容必定会刷到磁盘；</li>
<li>每次消息（及索引）写入后，如果没有后续写入请求，则会直接将已写入的索引刷到磁盘，实现上与消息的timeout刷盘一致。</li>
</ol>
</blockquote>

<h3>消息索引在磁盘文件中的格式</h3>

<p>每个队列会对队列中的消息维护一个索引，每入队列一个消息，索引加1，索引在持久化时，以2<sup>14</sup>个（16384）entry为单位组成一个文件（Segment）。索引在写入时，未必会按序写入，为了避免过多的磁盘寻址，索引信息会首先保存在Journal文件中，当该文件中的entry数量达到65536个时，会将其中的内容写入到Segment文件中。其中Journal保存于$MNESIA/queues/md5(queueName)/journal.jif文件中，索引保存于$MNESIA/queues/md5(queueName)/x.idx文件中，其中的x为数字编号，类似于消息文件的编号。</p>

<p>索引信息在Segment文件中的格式有两种：</p>

<blockquote><ol>
<li>对应publish消息：&lt;&lt;1:1, IsPersistent:1, RelSeq:14, MsgId:16/binary, Expiry:8/binary>>；</li>
<li>对应deliver或者ack消息：&lt;&lt;01:2, RelSeq:14>>。</li>
</ol>
</blockquote>

<h4>文件何时删除？</h4>

<p>rabbit_msg_index模块为每一个Segment维护一个unacked计数，每publish一个消息加1，每ack一个消息减1，当unacked=0时，文件删除。</p>

<p><strong>注：持久化文件的大小可通过配置参数msg_store_file_size_limit修改，journal文件中最大entry数量可通过参数queue_index_max_ journal_entries配置，具体参见<a href="http://www.rabbitmq.com/configure.html#config-items">这里</a></strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RabbitMQ HA机制]]></title>
    <link href="http://onlychoice.github.io/blog/2013/11/12/rabbitmq-ha/"/>
    <updated>2013-11-12T11:05:00+08:00</updated>
    <id>http://onlychoice.github.io/blog/2013/11/12/rabbitmq-ha</id>
    <content type="html"><![CDATA[<p>RabbitMQ为了保证消息不丢失，提供了高可用机制，或者称为镜像队列，详细文档可以参考<a href="http://www.rabbitmq.com/ha.html">这里</a>，本文试图搞清楚其实现细节。</p>

<!--more-->


<h2>创建高可用队列</h2>

<p>RabbitMQ在3.x之前是通过客户端在创建队列时传入特定参数还创建高可用队列的，3.x之后，所有高可用队列都是通过policy来管理，使用类似正则匹配的方式来决定哪些队列需要创建成镜像队列。</p>

<h3>与普通队列的差别</h3>

<p>普通队列只在创建结点上存在一个Erlang进程（amqqueue_process）来处理消息逻辑，而HA的队列存在两类进程：master进程（amqqueue_process）和slave进程（rabbit_mirror_queue_slave），每个进程包含一个实际用于处理消息逻辑的队列（rabbit_variable_queue）。整体结构如下图：</p>

<p><img src="/images/rabbit_ha.png" /></p>

<h2>消息流程</h2>

<h3>发送消息</h3>

<p>生产消息的事件会通过rabbit_channel进程同时广播到master和slave进程（异步），并且在master进程收到消息后，会再通过GM将该消息广播到所有slave进程（异步），也就是说对于生产消息的事件，slave进程会同时收到两个消息：一个从GM发来，一个从rabbit_channel进程发来。消息流如下图所示：</p>

<p><img src="/images/rabbit_ha_publish.png" /></p>

<p>代码里的文档对于为什么同时需要从channel发送消息到slave的解释如下：</p>

<blockquote><p>The key purpose of also sending messages directly from the channels
to the slaves is that without this, in the event of the death of
the master, messages could be lost until a suitable slave is
promoted. However, that is not the only reason. A slave cannot send
confirms for a message until it has seen it from the
channel. Otherwise, it might send a confirm to a channel for a
message that it might <em>never</em> receive from that channel. This can
happen because new slaves join the gm ring (and thus receive
messages from the master) before inserting themselves in the
queue&rsquo;s mnesia record (which is what channels look at for routing).
As it turns out, channels will simply ignore such bogus confirms,
but relying on that would introduce a dangerously tight coupling.</p></blockquote>

<p>也就是说不通过channel发送消息到slave进程可能会产生两个问题：</p>

<blockquote><ol>
<li>如果master进程挂掉了，消息有可能会丢失：master收到消息，广播到slave进程之前挂掉，slave进程就不可能通过GM收到该消息；</li>
<li>在slave进程已经加入到GM中，但是slave进程信息还没有写到mnesia数据库中时，slave进程可能只会收到从GM发送过来的消息，这时候，slave会发送一个从来没收到过的消息的confirm消息到channel进程；从上面的解释来看，RabbitMQ认为这样会带来强耦合的关系。</li>
</ol>
</blockquote>

<h3>confirm消息</h3>

<p>master进程及slave进程在实际队列完成消息入队工作（可能会持久化到磁盘）后，将会发送进程（rabbit_channel）发送一个confirm消息，rabbit_channel进程只有在收到所有队列进程（master及slave）的confirm消息后，才会向客户端发回confirm消息。</p>

<h3>消费消息</h3>

<p>所有消费消息的相关事件（获取消息，ack消息，requeue消息）都是只发送到master进程，然后由master进程通过GM来广播这些事件到所有slave进程。消息流如下图所示：</p>

<p><img src="/images/rabbit_ha_consume.png" /></p>

<h2>节点变化</h2>

<h3>新结点加入</h3>

<p>新的slave结点可以随时加入集群，但是加入之前的消息并不会同步到新的slave结点。也就是说在一开始，新的slave结点肯定会在一段时间内与master的内容不同步，随着旧消息被消费，新slave结点的内容会保持与master同步。</p>

<h3>Slave挂掉</h3>

<p>基本无影响，连接在这个slave上的客户端需要重新连接到其它结点。</p>

<h3>Master挂掉</h3>

<blockquote><ol>
<li>一个slave会被选举为新的master，要求这个slave为所有slave中最老的结点；</li>
<li>Slave认为所有之前的Consumer都突然断开，然后会requeue所有之前未ACK的消息（ACK可能未到已挂掉的Master或者已经到已挂掉的Master，但在广播到到Slave之前，Master挂掉），这种情况下，会导致客户端收到重复的消息；</li>
<li>未断开的Consumer会收到 Consumer Cancellation Notification，这时候Consumer应该重新订阅队列。</li>
</ol>
</blockquote>

<p>也就是说master结点的异常会产生两个问题：1）可能会丢消息；2）可能会收到重复消息。重复消息还可以接受（就算是普通队列也会面临这个问题，需要应用层来处理），但是丢消息对应用来说可能就会有点问题。</p>

<h2>运维</h2>

<h3>网络分区</h3>

<p>RabbitMQ提供了一个配置参数：cluster_partition_handling，可选值有三个：ignore，pause_minority，autoheal，具体什么意思可以参考<a href="http://www.rabbitmq.com/partitions.html">这里</a>。</p>

<p>也可以自己手动来解决：在发生网络分区时，选一个分区，把另一个分区的RabbitMQ全部重启一遍就可以重新组成集群。按官方的意思，在这之后，最好把整个集群重启一次才能清除掉警告信息。</p>
]]></content>
  </entry>
  
</feed>
